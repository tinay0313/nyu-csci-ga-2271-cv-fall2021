{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 1.2 - Computer Vision CSCI-GA.2272-001",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN5lM2csj9v7"
      },
      "source": [
        "# Computer Vision CSCI-GA.2272-001 Assignment 1, part 2.\n",
        "\n",
        "Fall 2021 semester.\n",
        "\n",
        "Due date: **September 30th 2021.**\n",
        "\n",
        "## Introduction\n",
        "This assignment requires you to participate in a Kaggle competition with the rest of the class on the The German Traffic Sign Recognition Benchmark [http://benchmark.ini.rub.de/?section=gtsrb&subsection=news]. The objective is to produce a model that gives the highest possible accuracy on the test portion of this dataset. You can register for the competition using the private link: https://www.kaggle.com/c/nyu-computer-vision-csci-ga2271-2021/overview.\n",
        "\n",
        "Skeleton code is provided in the colab below. This contains code for training a simple default model and evaluating it on the test set. The evaluation script produces a file gtsrb_kaggle.csv that lists the IDs of the test set images, along with their predicted label. This file should be uploaded to the Kaggle webpage, which will then produce a test accuracy score. \n",
        "\n",
        "Your goal is to implement a new model architecture that improves upon the baseline performance. You are free to implement any approach covered in class or from research papers. This part will count for 50% of the overall grade for assignment 1. This Grading will depend on your Kaggle performance and rank, as well as novelty of the architecture.  \n",
        "\n",
        "## Rules\n",
        "You should make a copy of this Colab (File->Save a copy in Drive). Please start the assignment early and don’t be afraid to ask for help from either the TAs or myself. You are allowed to collaborate with other students in terms discussing ideas and possible solutions. However you code up the solution yourself, i.e. you must write your own code. Copying your friends code and just changing all the names of the variables is not allowed! You are not allowed to use solutions from similar assignments in courses from other institutions, or those found elsewhere on the web.\n",
        "Your solutions should be submitted via the Brightspace system. This should include a brief description (in the Colab) explaining the model architectures you explored, citing any relevant papers or techniques that you used. You should also include convergence plots of training accuracy vs epoch for relevant models. \n",
        "\n",
        "### Important Details\n",
        "• You are only allowed eight (8) submissions to the Kaggle evaluation server per day. This is to prevent over-fitting on the test dataset. So be sure to start the assignment early!\n",
        "\n",
        "• You are NOT ALLOWED to use the test set labels during training in any way. Doing so will be regarded as cheating and penalized accordingly.\n",
        "\n",
        "• The evaluation metric is accuracy, i.e. the fraction of test set examples where the predicted label agrees with the ground truth label.\n",
        "\n",
        "• You should be able to achieve a test accuracy of at least 0.95. \n",
        "\n",
        "• *Extra important:* Please use your NYU NetID as your Kaggle username, so the TAs can figure out which user you are on the leaderboard. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pghx7ngowha0"
      },
      "source": [
        "# Dataset Preparation\n",
        "\n",
        "\n",
        "1.  Download `dataset.zip` from to your local machine.\n",
        "2.  Unzip the file. You should see a `dataset` directory with three subfolders (`training,validation,testing`). \n",
        "3.  Go to Google Drive (on your NYU account) and make a directory `assign2_dataset` (New button --> New Folder).\n",
        "4.  Upload each of the three subfolders to it (New button --> Folder upload). \n",
        "5.  Run the code block below. It will ask for permission to mount your Google Drive (NYU account) so this colab can access it. Paste the authorization code into the box as requested. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0aPnIKXpWbN",
        "outputId": "0d99c422-59a9-4522-d5d7-af8ec4a66263"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd  /content/drive/'My Drive'/assign2_dataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/assign2_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6jVfIVtrn5u"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z21UKj_bT--_"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "batch_size = 64\n",
        "momentum = 0.9\n",
        "lr = 0.01\n",
        "epochs = 30\n",
        "log_interval = 10\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X_path=\"X.pt\", y_path=\"y.pt\"):\n",
        "\n",
        "        self.X = torch.load(X_path).squeeze(1)\n",
        "        self.y = torch.load(y_path).squeeze(1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = MyDataset(X_path=\"train/X.pt\", y_path=\"train/y.pt\")\n",
        "val_dataset = MyDataset(X_path=\"validation/X.pt\", y_path=\"validation/y.pt\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd6W0pQRvZKO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vy23ilSomvd"
      },
      "source": [
        "**Model Selection Reason**\n",
        "\n",
        "The model incorporates concepts of the Network-In-Network model and extensive usage of batch normalization to increase computational speed.\n",
        "\n",
        "There are 2 blocks of convolutional layers followed by 2 fully-connected layers.\n",
        "\n",
        "Each convolutional layer is batch normalized so that the input feeding into the next convolutional layer (and when backpropagated) has lower variance. Max pooling is performed at the end of each convolutional block to reduce dimensionality. The ReLU non-linearity is used because it is the most widely used non-linearity in modern day models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meQqgTCpXyqY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "nclasses = 43 # GTSRB has 43 classes\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.feature_map = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 128, 3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2, ceil_mode=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.Conv2d(128, 192, 3),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.Conv2d(192, 96, 3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2, ceil_mode=True),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.Dropout(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(96 * 5 * 5, 80)\n",
        "        self.fc2 = nn.Linear(80, nclasses)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_map(x)\n",
        "        \n",
        "        # print(x.shape)\n",
        "        \n",
        "        # need to flatten output before fully-connected layers as\n",
        "        # they expect 1D vector as input\n",
        "        x = x.view(-1, 96 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x,dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty9TAvrdvf8C"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A5-OCgBvhXv"
      },
      "source": [
        "model = Net()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aby0gtT47Tkm",
        "outputId": "09986ea5-64de-4cfa-fe59-8aca16d87889"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model.cpu(), input_size=(3,32,32), device=\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 30, 30]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 30, 30]             128\n",
            "            Conv2d-3          [-1, 128, 28, 28]          73,856\n",
            "              ReLU-4          [-1, 128, 28, 28]               0\n",
            "         MaxPool2d-5          [-1, 128, 14, 14]               0\n",
            "       BatchNorm2d-6          [-1, 128, 14, 14]             256\n",
            "            Conv2d-7          [-1, 192, 12, 12]         221,376\n",
            "       BatchNorm2d-8          [-1, 192, 12, 12]             384\n",
            "            Conv2d-9           [-1, 96, 10, 10]         165,984\n",
            "             ReLU-10           [-1, 96, 10, 10]               0\n",
            "        MaxPool2d-11             [-1, 96, 5, 5]               0\n",
            "      BatchNorm2d-12             [-1, 96, 5, 5]             192\n",
            "          Dropout-13             [-1, 96, 5, 5]               0\n",
            "           Linear-14                   [-1, 80]         192,080\n",
            "           Linear-15                   [-1, 43]           3,483\n",
            "================================================================\n",
            "Total params: 659,531\n",
            "Trainable params: 659,531\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.42\n",
            "Params size (MB): 2.52\n",
            "Estimated Total Size (MB): 5.94\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sniOLnh25gwk",
        "outputId": "04588a87-b8b1-4cb5-f3ea-4345aae7a594"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "best_validation_accuracy = 0.0\n",
        "curr_validation_accuracy = 0.0\n",
        "best_epoch = 1\n",
        "training_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    \n",
        "    return 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "def validation():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in val_loader:\n",
        "        output = model(data)\n",
        "        validation_loss += F.nll_loss(output, target, reduction=\"sum\").item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    validation_loss /= len(val_loader.dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        validation_loss, correct, len(val_loader.dataset),\n",
        "        100. * correct / len(val_loader.dataset)))\n",
        "    return 100. * correct / len(val_loader.dataset)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    curr_training_accuracy = train(epoch)\n",
        "    curr_validation_accuracy = validation()\n",
        "    \n",
        "    training_accuracy.append(curr_training_accuracy)\n",
        "    validation_accuracy.append(curr_validation_accuracy)\n",
        "    \n",
        "    model_file = 'model_' + str(epoch) + '.pth'\n",
        "    torch.save(model.state_dict(), model_file)\n",
        "    print('\\nSaved model to ' + model_file + '.')\n",
        "    if curr_validation_accuracy > best_validation_accuracy:\n",
        "      best_validation_accuracy = curr_validation_accuracy\n",
        "      best_epoch = epoch\n",
        "      print('\\nMost accurate epoch so far: {}'.format(best_epoch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/35339 (0%)]\tLoss: 3.931246\n",
            "Train Epoch: 1 [640/35339 (2%)]\tLoss: 3.232257\n",
            "Train Epoch: 1 [1280/35339 (4%)]\tLoss: 2.949193\n",
            "Train Epoch: 1 [1920/35339 (5%)]\tLoss: 2.310938\n",
            "Train Epoch: 1 [2560/35339 (7%)]\tLoss: 2.316420\n",
            "Train Epoch: 1 [3200/35339 (9%)]\tLoss: 1.676103\n",
            "Train Epoch: 1 [3840/35339 (11%)]\tLoss: 1.736788\n",
            "Train Epoch: 1 [4480/35339 (13%)]\tLoss: 1.754452\n",
            "Train Epoch: 1 [5120/35339 (14%)]\tLoss: 1.458635\n",
            "Train Epoch: 1 [5760/35339 (16%)]\tLoss: 1.481479\n",
            "Train Epoch: 1 [6400/35339 (18%)]\tLoss: 1.238352\n",
            "Train Epoch: 1 [7040/35339 (20%)]\tLoss: 1.110657\n",
            "Train Epoch: 1 [7680/35339 (22%)]\tLoss: 0.895336\n",
            "Train Epoch: 1 [8320/35339 (24%)]\tLoss: 0.761815\n",
            "Train Epoch: 1 [8960/35339 (25%)]\tLoss: 0.916237\n",
            "Train Epoch: 1 [9600/35339 (27%)]\tLoss: 0.800413\n",
            "Train Epoch: 1 [10240/35339 (29%)]\tLoss: 0.757459\n",
            "Train Epoch: 1 [10880/35339 (31%)]\tLoss: 0.499960\n",
            "Train Epoch: 1 [11520/35339 (33%)]\tLoss: 0.646698\n",
            "Train Epoch: 1 [12160/35339 (34%)]\tLoss: 0.646262\n",
            "Train Epoch: 1 [12800/35339 (36%)]\tLoss: 0.684347\n",
            "Train Epoch: 1 [13440/35339 (38%)]\tLoss: 0.579354\n",
            "Train Epoch: 1 [14080/35339 (40%)]\tLoss: 0.492716\n",
            "Train Epoch: 1 [14720/35339 (42%)]\tLoss: 0.434602\n",
            "Train Epoch: 1 [15360/35339 (43%)]\tLoss: 0.556458\n",
            "Train Epoch: 1 [16000/35339 (45%)]\tLoss: 0.303598\n",
            "Train Epoch: 1 [16640/35339 (47%)]\tLoss: 0.626643\n",
            "Train Epoch: 1 [17280/35339 (49%)]\tLoss: 0.512129\n",
            "Train Epoch: 1 [17920/35339 (51%)]\tLoss: 0.647911\n",
            "Train Epoch: 1 [18560/35339 (52%)]\tLoss: 0.303734\n",
            "Train Epoch: 1 [19200/35339 (54%)]\tLoss: 0.490346\n",
            "Train Epoch: 1 [19840/35339 (56%)]\tLoss: 0.278695\n",
            "Train Epoch: 1 [20480/35339 (58%)]\tLoss: 0.434242\n",
            "Train Epoch: 1 [21120/35339 (60%)]\tLoss: 0.474740\n",
            "Train Epoch: 1 [21760/35339 (61%)]\tLoss: 0.366298\n",
            "Train Epoch: 1 [22400/35339 (63%)]\tLoss: 0.433671\n",
            "Train Epoch: 1 [23040/35339 (65%)]\tLoss: 0.297446\n",
            "Train Epoch: 1 [23680/35339 (67%)]\tLoss: 0.386034\n",
            "Train Epoch: 1 [24320/35339 (69%)]\tLoss: 0.320865\n",
            "Train Epoch: 1 [24960/35339 (71%)]\tLoss: 0.327179\n",
            "Train Epoch: 1 [25600/35339 (72%)]\tLoss: 0.388930\n",
            "Train Epoch: 1 [26240/35339 (74%)]\tLoss: 0.192071\n",
            "Train Epoch: 1 [26880/35339 (76%)]\tLoss: 0.354836\n",
            "Train Epoch: 1 [27520/35339 (78%)]\tLoss: 0.241004\n",
            "Train Epoch: 1 [28160/35339 (80%)]\tLoss: 0.235616\n",
            "Train Epoch: 1 [28800/35339 (81%)]\tLoss: 0.261982\n",
            "Train Epoch: 1 [29440/35339 (83%)]\tLoss: 0.129241\n",
            "Train Epoch: 1 [30080/35339 (85%)]\tLoss: 0.319084\n",
            "Train Epoch: 1 [30720/35339 (87%)]\tLoss: 0.335291\n",
            "Train Epoch: 1 [31360/35339 (89%)]\tLoss: 0.455683\n",
            "Train Epoch: 1 [32000/35339 (90%)]\tLoss: 0.175824\n",
            "Train Epoch: 1 [32640/35339 (92%)]\tLoss: 0.465934\n",
            "Train Epoch: 1 [33280/35339 (94%)]\tLoss: 0.303011\n",
            "Train Epoch: 1 [33920/35339 (96%)]\tLoss: 0.309593\n",
            "Train Epoch: 1 [34560/35339 (98%)]\tLoss: 0.224139\n",
            "Train Epoch: 1 [35200/35339 (99%)]\tLoss: 0.152396\n",
            "\n",
            "Validation set: Average loss: 0.3109, Accuracy: 3546/3870 (92%)\n",
            "\n",
            "\n",
            "Saved model to model_1.pth.\n",
            "\n",
            "Most accurate epoch so far: 1\n",
            "Train Epoch: 2 [0/35339 (0%)]\tLoss: 0.313047\n",
            "Train Epoch: 2 [640/35339 (2%)]\tLoss: 0.175446\n",
            "Train Epoch: 2 [1280/35339 (4%)]\tLoss: 0.416060\n",
            "Train Epoch: 2 [1920/35339 (5%)]\tLoss: 0.335219\n",
            "Train Epoch: 2 [2560/35339 (7%)]\tLoss: 0.213722\n",
            "Train Epoch: 2 [3200/35339 (9%)]\tLoss: 0.275812\n",
            "Train Epoch: 2 [3840/35339 (11%)]\tLoss: 0.122308\n",
            "Train Epoch: 2 [4480/35339 (13%)]\tLoss: 0.180983\n",
            "Train Epoch: 2 [5120/35339 (14%)]\tLoss: 0.135842\n",
            "Train Epoch: 2 [5760/35339 (16%)]\tLoss: 0.190030\n",
            "Train Epoch: 2 [6400/35339 (18%)]\tLoss: 0.144034\n",
            "Train Epoch: 2 [7040/35339 (20%)]\tLoss: 0.189470\n",
            "Train Epoch: 2 [7680/35339 (22%)]\tLoss: 0.250324\n",
            "Train Epoch: 2 [8320/35339 (24%)]\tLoss: 0.208070\n",
            "Train Epoch: 2 [8960/35339 (25%)]\tLoss: 0.319867\n",
            "Train Epoch: 2 [9600/35339 (27%)]\tLoss: 0.278427\n",
            "Train Epoch: 2 [10240/35339 (29%)]\tLoss: 0.167438\n",
            "Train Epoch: 2 [10880/35339 (31%)]\tLoss: 0.094190\n",
            "Train Epoch: 2 [11520/35339 (33%)]\tLoss: 0.256031\n",
            "Train Epoch: 2 [12160/35339 (34%)]\tLoss: 0.122823\n",
            "Train Epoch: 2 [12800/35339 (36%)]\tLoss: 0.200677\n",
            "Train Epoch: 2 [13440/35339 (38%)]\tLoss: 0.189039\n",
            "Train Epoch: 2 [14080/35339 (40%)]\tLoss: 0.151543\n",
            "Train Epoch: 2 [14720/35339 (42%)]\tLoss: 0.151929\n",
            "Train Epoch: 2 [15360/35339 (43%)]\tLoss: 0.169444\n",
            "Train Epoch: 2 [16000/35339 (45%)]\tLoss: 0.139385\n",
            "Train Epoch: 2 [16640/35339 (47%)]\tLoss: 0.120327\n",
            "Train Epoch: 2 [17280/35339 (49%)]\tLoss: 0.146101\n",
            "Train Epoch: 2 [17920/35339 (51%)]\tLoss: 0.190485\n",
            "Train Epoch: 2 [18560/35339 (52%)]\tLoss: 0.042902\n",
            "Train Epoch: 2 [19200/35339 (54%)]\tLoss: 0.304931\n",
            "Train Epoch: 2 [19840/35339 (56%)]\tLoss: 0.100051\n",
            "Train Epoch: 2 [20480/35339 (58%)]\tLoss: 0.152964\n",
            "Train Epoch: 2 [21120/35339 (60%)]\tLoss: 0.178675\n",
            "Train Epoch: 2 [21760/35339 (61%)]\tLoss: 0.162576\n",
            "Train Epoch: 2 [22400/35339 (63%)]\tLoss: 0.147705\n",
            "Train Epoch: 2 [23040/35339 (65%)]\tLoss: 0.133823\n",
            "Train Epoch: 2 [23680/35339 (67%)]\tLoss: 0.135136\n",
            "Train Epoch: 2 [24320/35339 (69%)]\tLoss: 0.158198\n",
            "Train Epoch: 2 [24960/35339 (71%)]\tLoss: 0.125235\n",
            "Train Epoch: 2 [25600/35339 (72%)]\tLoss: 0.361818\n",
            "Train Epoch: 2 [26240/35339 (74%)]\tLoss: 0.195591\n",
            "Train Epoch: 2 [26880/35339 (76%)]\tLoss: 0.147742\n",
            "Train Epoch: 2 [27520/35339 (78%)]\tLoss: 0.181533\n",
            "Train Epoch: 2 [28160/35339 (80%)]\tLoss: 0.150349\n",
            "Train Epoch: 2 [28800/35339 (81%)]\tLoss: 0.133250\n",
            "Train Epoch: 2 [29440/35339 (83%)]\tLoss: 0.100287\n",
            "Train Epoch: 2 [30080/35339 (85%)]\tLoss: 0.162967\n",
            "Train Epoch: 2 [30720/35339 (87%)]\tLoss: 0.132717\n",
            "Train Epoch: 2 [31360/35339 (89%)]\tLoss: 0.182646\n",
            "Train Epoch: 2 [32000/35339 (90%)]\tLoss: 0.137323\n",
            "Train Epoch: 2 [32640/35339 (92%)]\tLoss: 0.073684\n",
            "Train Epoch: 2 [33280/35339 (94%)]\tLoss: 0.218752\n",
            "Train Epoch: 2 [33920/35339 (96%)]\tLoss: 0.042140\n",
            "Train Epoch: 2 [34560/35339 (98%)]\tLoss: 0.087821\n",
            "Train Epoch: 2 [35200/35339 (99%)]\tLoss: 0.186884\n",
            "\n",
            "Validation set: Average loss: 0.2006, Accuracy: 3651/3870 (94%)\n",
            "\n",
            "\n",
            "Saved model to model_2.pth.\n",
            "\n",
            "Most accurate epoch so far: 2\n",
            "Train Epoch: 3 [0/35339 (0%)]\tLoss: 0.175359\n",
            "Train Epoch: 3 [640/35339 (2%)]\tLoss: 0.035035\n",
            "Train Epoch: 3 [1280/35339 (4%)]\tLoss: 0.114634\n",
            "Train Epoch: 3 [1920/35339 (5%)]\tLoss: 0.083849\n",
            "Train Epoch: 3 [2560/35339 (7%)]\tLoss: 0.053659\n",
            "Train Epoch: 3 [3200/35339 (9%)]\tLoss: 0.161520\n",
            "Train Epoch: 3 [3840/35339 (11%)]\tLoss: 0.198852\n",
            "Train Epoch: 3 [4480/35339 (13%)]\tLoss: 0.222958\n",
            "Train Epoch: 3 [5120/35339 (14%)]\tLoss: 0.113816\n",
            "Train Epoch: 3 [5760/35339 (16%)]\tLoss: 0.088888\n",
            "Train Epoch: 3 [6400/35339 (18%)]\tLoss: 0.104956\n",
            "Train Epoch: 3 [7040/35339 (20%)]\tLoss: 0.099331\n",
            "Train Epoch: 3 [7680/35339 (22%)]\tLoss: 0.287703\n",
            "Train Epoch: 3 [8320/35339 (24%)]\tLoss: 0.092045\n",
            "Train Epoch: 3 [8960/35339 (25%)]\tLoss: 0.178194\n",
            "Train Epoch: 3 [9600/35339 (27%)]\tLoss: 0.109449\n",
            "Train Epoch: 3 [10240/35339 (29%)]\tLoss: 0.169291\n",
            "Train Epoch: 3 [10880/35339 (31%)]\tLoss: 0.056706\n",
            "Train Epoch: 3 [11520/35339 (33%)]\tLoss: 0.130785\n",
            "Train Epoch: 3 [12160/35339 (34%)]\tLoss: 0.045273\n",
            "Train Epoch: 3 [12800/35339 (36%)]\tLoss: 0.138725\n",
            "Train Epoch: 3 [13440/35339 (38%)]\tLoss: 0.020144\n",
            "Train Epoch: 3 [14080/35339 (40%)]\tLoss: 0.078540\n",
            "Train Epoch: 3 [14720/35339 (42%)]\tLoss: 0.237641\n",
            "Train Epoch: 3 [15360/35339 (43%)]\tLoss: 0.127477\n",
            "Train Epoch: 3 [16000/35339 (45%)]\tLoss: 0.120468\n",
            "Train Epoch: 3 [16640/35339 (47%)]\tLoss: 0.183896\n",
            "Train Epoch: 3 [17280/35339 (49%)]\tLoss: 0.045884\n",
            "Train Epoch: 3 [17920/35339 (51%)]\tLoss: 0.051720\n",
            "Train Epoch: 3 [18560/35339 (52%)]\tLoss: 0.075351\n",
            "Train Epoch: 3 [19200/35339 (54%)]\tLoss: 0.059329\n",
            "Train Epoch: 3 [19840/35339 (56%)]\tLoss: 0.056845\n",
            "Train Epoch: 3 [20480/35339 (58%)]\tLoss: 0.598828\n",
            "Train Epoch: 3 [21120/35339 (60%)]\tLoss: 0.080468\n",
            "Train Epoch: 3 [21760/35339 (61%)]\tLoss: 0.062018\n",
            "Train Epoch: 3 [22400/35339 (63%)]\tLoss: 0.144369\n",
            "Train Epoch: 3 [23040/35339 (65%)]\tLoss: 0.169947\n",
            "Train Epoch: 3 [23680/35339 (67%)]\tLoss: 0.068412\n",
            "Train Epoch: 3 [24320/35339 (69%)]\tLoss: 0.043004\n",
            "Train Epoch: 3 [24960/35339 (71%)]\tLoss: 0.101098\n",
            "Train Epoch: 3 [25600/35339 (72%)]\tLoss: 0.049798\n",
            "Train Epoch: 3 [26240/35339 (74%)]\tLoss: 0.215594\n",
            "Train Epoch: 3 [26880/35339 (76%)]\tLoss: 0.083134\n",
            "Train Epoch: 3 [27520/35339 (78%)]\tLoss: 0.224196\n",
            "Train Epoch: 3 [28160/35339 (80%)]\tLoss: 0.147988\n",
            "Train Epoch: 3 [28800/35339 (81%)]\tLoss: 0.100215\n",
            "Train Epoch: 3 [29440/35339 (83%)]\tLoss: 0.040755\n",
            "Train Epoch: 3 [30080/35339 (85%)]\tLoss: 0.031765\n",
            "Train Epoch: 3 [30720/35339 (87%)]\tLoss: 0.086664\n",
            "Train Epoch: 3 [31360/35339 (89%)]\tLoss: 0.192281\n",
            "Train Epoch: 3 [32000/35339 (90%)]\tLoss: 0.054441\n",
            "Train Epoch: 3 [32640/35339 (92%)]\tLoss: 0.083619\n",
            "Train Epoch: 3 [33280/35339 (94%)]\tLoss: 0.117010\n",
            "Train Epoch: 3 [33920/35339 (96%)]\tLoss: 0.025847\n",
            "Train Epoch: 3 [34560/35339 (98%)]\tLoss: 0.263297\n",
            "Train Epoch: 3 [35200/35339 (99%)]\tLoss: 0.094680\n",
            "\n",
            "Validation set: Average loss: 0.1540, Accuracy: 3700/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_3.pth.\n",
            "\n",
            "Most accurate epoch so far: 3\n",
            "Train Epoch: 4 [0/35339 (0%)]\tLoss: 0.019320\n",
            "Train Epoch: 4 [640/35339 (2%)]\tLoss: 0.132562\n",
            "Train Epoch: 4 [1280/35339 (4%)]\tLoss: 0.067819\n",
            "Train Epoch: 4 [1920/35339 (5%)]\tLoss: 0.075771\n",
            "Train Epoch: 4 [2560/35339 (7%)]\tLoss: 0.278848\n",
            "Train Epoch: 4 [3200/35339 (9%)]\tLoss: 0.092287\n",
            "Train Epoch: 4 [3840/35339 (11%)]\tLoss: 0.050744\n",
            "Train Epoch: 4 [4480/35339 (13%)]\tLoss: 0.138848\n",
            "Train Epoch: 4 [5120/35339 (14%)]\tLoss: 0.050673\n",
            "Train Epoch: 4 [5760/35339 (16%)]\tLoss: 0.089302\n",
            "Train Epoch: 4 [6400/35339 (18%)]\tLoss: 0.244803\n",
            "Train Epoch: 4 [7040/35339 (20%)]\tLoss: 0.133020\n",
            "Train Epoch: 4 [7680/35339 (22%)]\tLoss: 0.062629\n",
            "Train Epoch: 4 [8320/35339 (24%)]\tLoss: 0.063430\n",
            "Train Epoch: 4 [8960/35339 (25%)]\tLoss: 0.058306\n",
            "Train Epoch: 4 [9600/35339 (27%)]\tLoss: 0.039844\n",
            "Train Epoch: 4 [10240/35339 (29%)]\tLoss: 0.072959\n",
            "Train Epoch: 4 [10880/35339 (31%)]\tLoss: 0.033804\n",
            "Train Epoch: 4 [11520/35339 (33%)]\tLoss: 0.076949\n",
            "Train Epoch: 4 [12160/35339 (34%)]\tLoss: 0.094982\n",
            "Train Epoch: 4 [12800/35339 (36%)]\tLoss: 0.133532\n",
            "Train Epoch: 4 [13440/35339 (38%)]\tLoss: 0.143585\n",
            "Train Epoch: 4 [14080/35339 (40%)]\tLoss: 0.109568\n",
            "Train Epoch: 4 [14720/35339 (42%)]\tLoss: 0.051208\n",
            "Train Epoch: 4 [15360/35339 (43%)]\tLoss: 0.037906\n",
            "Train Epoch: 4 [16000/35339 (45%)]\tLoss: 0.227294\n",
            "Train Epoch: 4 [16640/35339 (47%)]\tLoss: 0.041251\n",
            "Train Epoch: 4 [17280/35339 (49%)]\tLoss: 0.076140\n",
            "Train Epoch: 4 [17920/35339 (51%)]\tLoss: 0.109157\n",
            "Train Epoch: 4 [18560/35339 (52%)]\tLoss: 0.032729\n",
            "Train Epoch: 4 [19200/35339 (54%)]\tLoss: 0.250038\n",
            "Train Epoch: 4 [19840/35339 (56%)]\tLoss: 0.071937\n",
            "Train Epoch: 4 [20480/35339 (58%)]\tLoss: 0.055417\n",
            "Train Epoch: 4 [21120/35339 (60%)]\tLoss: 0.027941\n",
            "Train Epoch: 4 [21760/35339 (61%)]\tLoss: 0.097819\n",
            "Train Epoch: 4 [22400/35339 (63%)]\tLoss: 0.092020\n",
            "Train Epoch: 4 [23040/35339 (65%)]\tLoss: 0.043877\n",
            "Train Epoch: 4 [23680/35339 (67%)]\tLoss: 0.042923\n",
            "Train Epoch: 4 [24320/35339 (69%)]\tLoss: 0.075419\n",
            "Train Epoch: 4 [24960/35339 (71%)]\tLoss: 0.155370\n",
            "Train Epoch: 4 [25600/35339 (72%)]\tLoss: 0.073641\n",
            "Train Epoch: 4 [26240/35339 (74%)]\tLoss: 0.236195\n",
            "Train Epoch: 4 [26880/35339 (76%)]\tLoss: 0.170706\n",
            "Train Epoch: 4 [27520/35339 (78%)]\tLoss: 0.073795\n",
            "Train Epoch: 4 [28160/35339 (80%)]\tLoss: 0.060988\n",
            "Train Epoch: 4 [28800/35339 (81%)]\tLoss: 0.059086\n",
            "Train Epoch: 4 [29440/35339 (83%)]\tLoss: 0.083608\n",
            "Train Epoch: 4 [30080/35339 (85%)]\tLoss: 0.168800\n",
            "Train Epoch: 4 [30720/35339 (87%)]\tLoss: 0.054285\n",
            "Train Epoch: 4 [31360/35339 (89%)]\tLoss: 0.114463\n",
            "Train Epoch: 4 [32000/35339 (90%)]\tLoss: 0.068805\n",
            "Train Epoch: 4 [32640/35339 (92%)]\tLoss: 0.169005\n",
            "Train Epoch: 4 [33280/35339 (94%)]\tLoss: 0.246209\n",
            "Train Epoch: 4 [33920/35339 (96%)]\tLoss: 0.066046\n",
            "Train Epoch: 4 [34560/35339 (98%)]\tLoss: 0.065480\n",
            "Train Epoch: 4 [35200/35339 (99%)]\tLoss: 0.044105\n",
            "\n",
            "Validation set: Average loss: 0.1693, Accuracy: 3685/3870 (95%)\n",
            "\n",
            "\n",
            "Saved model to model_4.pth.\n",
            "Train Epoch: 5 [0/35339 (0%)]\tLoss: 0.015598\n",
            "Train Epoch: 5 [640/35339 (2%)]\tLoss: 0.110708\n",
            "Train Epoch: 5 [1280/35339 (4%)]\tLoss: 0.046829\n",
            "Train Epoch: 5 [1920/35339 (5%)]\tLoss: 0.036609\n",
            "Train Epoch: 5 [2560/35339 (7%)]\tLoss: 0.093247\n",
            "Train Epoch: 5 [3200/35339 (9%)]\tLoss: 0.024014\n",
            "Train Epoch: 5 [3840/35339 (11%)]\tLoss: 0.228056\n",
            "Train Epoch: 5 [4480/35339 (13%)]\tLoss: 0.149755\n",
            "Train Epoch: 5 [5120/35339 (14%)]\tLoss: 0.067038\n",
            "Train Epoch: 5 [5760/35339 (16%)]\tLoss: 0.028881\n",
            "Train Epoch: 5 [6400/35339 (18%)]\tLoss: 0.016793\n",
            "Train Epoch: 5 [7040/35339 (20%)]\tLoss: 0.034885\n",
            "Train Epoch: 5 [7680/35339 (22%)]\tLoss: 0.172618\n",
            "Train Epoch: 5 [8320/35339 (24%)]\tLoss: 0.102345\n",
            "Train Epoch: 5 [8960/35339 (25%)]\tLoss: 0.307633\n",
            "Train Epoch: 5 [9600/35339 (27%)]\tLoss: 0.085110\n",
            "Train Epoch: 5 [10240/35339 (29%)]\tLoss: 0.090051\n",
            "Train Epoch: 5 [10880/35339 (31%)]\tLoss: 0.053966\n",
            "Train Epoch: 5 [11520/35339 (33%)]\tLoss: 0.061269\n",
            "Train Epoch: 5 [12160/35339 (34%)]\tLoss: 0.128165\n",
            "Train Epoch: 5 [12800/35339 (36%)]\tLoss: 0.111060\n",
            "Train Epoch: 5 [13440/35339 (38%)]\tLoss: 0.040403\n",
            "Train Epoch: 5 [14080/35339 (40%)]\tLoss: 0.192348\n",
            "Train Epoch: 5 [14720/35339 (42%)]\tLoss: 0.104248\n",
            "Train Epoch: 5 [15360/35339 (43%)]\tLoss: 0.171374\n",
            "Train Epoch: 5 [16000/35339 (45%)]\tLoss: 0.074987\n",
            "Train Epoch: 5 [16640/35339 (47%)]\tLoss: 0.194072\n",
            "Train Epoch: 5 [17280/35339 (49%)]\tLoss: 0.018620\n",
            "Train Epoch: 5 [17920/35339 (51%)]\tLoss: 0.054103\n",
            "Train Epoch: 5 [18560/35339 (52%)]\tLoss: 0.126618\n",
            "Train Epoch: 5 [19200/35339 (54%)]\tLoss: 0.055258\n",
            "Train Epoch: 5 [19840/35339 (56%)]\tLoss: 0.053583\n",
            "Train Epoch: 5 [20480/35339 (58%)]\tLoss: 0.065064\n",
            "Train Epoch: 5 [21120/35339 (60%)]\tLoss: 0.032637\n",
            "Train Epoch: 5 [21760/35339 (61%)]\tLoss: 0.121710\n",
            "Train Epoch: 5 [22400/35339 (63%)]\tLoss: 0.321462\n",
            "Train Epoch: 5 [23040/35339 (65%)]\tLoss: 0.013103\n",
            "Train Epoch: 5 [23680/35339 (67%)]\tLoss: 0.035605\n",
            "Train Epoch: 5 [24320/35339 (69%)]\tLoss: 0.100128\n",
            "Train Epoch: 5 [24960/35339 (71%)]\tLoss: 0.054236\n",
            "Train Epoch: 5 [25600/35339 (72%)]\tLoss: 0.070480\n",
            "Train Epoch: 5 [26240/35339 (74%)]\tLoss: 0.067383\n",
            "Train Epoch: 5 [26880/35339 (76%)]\tLoss: 0.003119\n",
            "Train Epoch: 5 [27520/35339 (78%)]\tLoss: 0.093157\n",
            "Train Epoch: 5 [28160/35339 (80%)]\tLoss: 0.077246\n",
            "Train Epoch: 5 [28800/35339 (81%)]\tLoss: 0.038924\n",
            "Train Epoch: 5 [29440/35339 (83%)]\tLoss: 0.063123\n",
            "Train Epoch: 5 [30080/35339 (85%)]\tLoss: 0.036853\n",
            "Train Epoch: 5 [30720/35339 (87%)]\tLoss: 0.016575\n",
            "Train Epoch: 5 [31360/35339 (89%)]\tLoss: 0.008474\n",
            "Train Epoch: 5 [32000/35339 (90%)]\tLoss: 0.097096\n",
            "Train Epoch: 5 [32640/35339 (92%)]\tLoss: 0.095130\n",
            "Train Epoch: 5 [33280/35339 (94%)]\tLoss: 0.005726\n",
            "Train Epoch: 5 [33920/35339 (96%)]\tLoss: 0.060717\n",
            "Train Epoch: 5 [34560/35339 (98%)]\tLoss: 0.160522\n",
            "Train Epoch: 5 [35200/35339 (99%)]\tLoss: 0.018141\n",
            "\n",
            "Validation set: Average loss: 0.1396, Accuracy: 3712/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_5.pth.\n",
            "\n",
            "Most accurate epoch so far: 5\n",
            "Train Epoch: 6 [0/35339 (0%)]\tLoss: 0.027491\n",
            "Train Epoch: 6 [640/35339 (2%)]\tLoss: 0.020801\n",
            "Train Epoch: 6 [1280/35339 (4%)]\tLoss: 0.067729\n",
            "Train Epoch: 6 [1920/35339 (5%)]\tLoss: 0.025351\n",
            "Train Epoch: 6 [2560/35339 (7%)]\tLoss: 0.017442\n",
            "Train Epoch: 6 [3200/35339 (9%)]\tLoss: 0.061603\n",
            "Train Epoch: 6 [3840/35339 (11%)]\tLoss: 0.021923\n",
            "Train Epoch: 6 [4480/35339 (13%)]\tLoss: 0.005562\n",
            "Train Epoch: 6 [5120/35339 (14%)]\tLoss: 0.060661\n",
            "Train Epoch: 6 [5760/35339 (16%)]\tLoss: 0.083137\n",
            "Train Epoch: 6 [6400/35339 (18%)]\tLoss: 0.029385\n",
            "Train Epoch: 6 [7040/35339 (20%)]\tLoss: 0.062739\n",
            "Train Epoch: 6 [7680/35339 (22%)]\tLoss: 0.094976\n",
            "Train Epoch: 6 [8320/35339 (24%)]\tLoss: 0.076768\n",
            "Train Epoch: 6 [8960/35339 (25%)]\tLoss: 0.085389\n",
            "Train Epoch: 6 [9600/35339 (27%)]\tLoss: 0.052950\n",
            "Train Epoch: 6 [10240/35339 (29%)]\tLoss: 0.013788\n",
            "Train Epoch: 6 [10880/35339 (31%)]\tLoss: 0.154468\n",
            "Train Epoch: 6 [11520/35339 (33%)]\tLoss: 0.126155\n",
            "Train Epoch: 6 [12160/35339 (34%)]\tLoss: 0.096593\n",
            "Train Epoch: 6 [12800/35339 (36%)]\tLoss: 0.024093\n",
            "Train Epoch: 6 [13440/35339 (38%)]\tLoss: 0.128828\n",
            "Train Epoch: 6 [14080/35339 (40%)]\tLoss: 0.080480\n",
            "Train Epoch: 6 [14720/35339 (42%)]\tLoss: 0.015218\n",
            "Train Epoch: 6 [15360/35339 (43%)]\tLoss: 0.103124\n",
            "Train Epoch: 6 [16000/35339 (45%)]\tLoss: 0.119428\n",
            "Train Epoch: 6 [16640/35339 (47%)]\tLoss: 0.038008\n",
            "Train Epoch: 6 [17280/35339 (49%)]\tLoss: 0.016352\n",
            "Train Epoch: 6 [17920/35339 (51%)]\tLoss: 0.037668\n",
            "Train Epoch: 6 [18560/35339 (52%)]\tLoss: 0.102157\n",
            "Train Epoch: 6 [19200/35339 (54%)]\tLoss: 0.081469\n",
            "Train Epoch: 6 [19840/35339 (56%)]\tLoss: 0.040816\n",
            "Train Epoch: 6 [20480/35339 (58%)]\tLoss: 0.119935\n",
            "Train Epoch: 6 [21120/35339 (60%)]\tLoss: 0.012532\n",
            "Train Epoch: 6 [21760/35339 (61%)]\tLoss: 0.008478\n",
            "Train Epoch: 6 [22400/35339 (63%)]\tLoss: 0.138321\n",
            "Train Epoch: 6 [23040/35339 (65%)]\tLoss: 0.325796\n",
            "Train Epoch: 6 [23680/35339 (67%)]\tLoss: 0.121834\n",
            "Train Epoch: 6 [24320/35339 (69%)]\tLoss: 0.152926\n",
            "Train Epoch: 6 [24960/35339 (71%)]\tLoss: 0.057818\n",
            "Train Epoch: 6 [25600/35339 (72%)]\tLoss: 0.055075\n",
            "Train Epoch: 6 [26240/35339 (74%)]\tLoss: 0.084840\n",
            "Train Epoch: 6 [26880/35339 (76%)]\tLoss: 0.109384\n",
            "Train Epoch: 6 [27520/35339 (78%)]\tLoss: 0.033800\n",
            "Train Epoch: 6 [28160/35339 (80%)]\tLoss: 0.078487\n",
            "Train Epoch: 6 [28800/35339 (81%)]\tLoss: 0.073752\n",
            "Train Epoch: 6 [29440/35339 (83%)]\tLoss: 0.026136\n",
            "Train Epoch: 6 [30080/35339 (85%)]\tLoss: 0.093533\n",
            "Train Epoch: 6 [30720/35339 (87%)]\tLoss: 0.130452\n",
            "Train Epoch: 6 [31360/35339 (89%)]\tLoss: 0.021148\n",
            "Train Epoch: 6 [32000/35339 (90%)]\tLoss: 0.078960\n",
            "Train Epoch: 6 [32640/35339 (92%)]\tLoss: 0.093165\n",
            "Train Epoch: 6 [33280/35339 (94%)]\tLoss: 0.157145\n",
            "Train Epoch: 6 [33920/35339 (96%)]\tLoss: 0.105821\n",
            "Train Epoch: 6 [34560/35339 (98%)]\tLoss: 0.146560\n",
            "Train Epoch: 6 [35200/35339 (99%)]\tLoss: 0.005427\n",
            "\n",
            "Validation set: Average loss: 0.1576, Accuracy: 3698/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_6.pth.\n",
            "Train Epoch: 7 [0/35339 (0%)]\tLoss: 0.046405\n",
            "Train Epoch: 7 [640/35339 (2%)]\tLoss: 0.124503\n",
            "Train Epoch: 7 [1280/35339 (4%)]\tLoss: 0.041608\n",
            "Train Epoch: 7 [1920/35339 (5%)]\tLoss: 0.116075\n",
            "Train Epoch: 7 [2560/35339 (7%)]\tLoss: 0.037015\n",
            "Train Epoch: 7 [3200/35339 (9%)]\tLoss: 0.022137\n",
            "Train Epoch: 7 [3840/35339 (11%)]\tLoss: 0.060853\n",
            "Train Epoch: 7 [4480/35339 (13%)]\tLoss: 0.052047\n",
            "Train Epoch: 7 [5120/35339 (14%)]\tLoss: 0.113263\n",
            "Train Epoch: 7 [5760/35339 (16%)]\tLoss: 0.025753\n",
            "Train Epoch: 7 [6400/35339 (18%)]\tLoss: 0.089754\n",
            "Train Epoch: 7 [7040/35339 (20%)]\tLoss: 0.068184\n",
            "Train Epoch: 7 [7680/35339 (22%)]\tLoss: 0.018371\n",
            "Train Epoch: 7 [8320/35339 (24%)]\tLoss: 0.180516\n",
            "Train Epoch: 7 [8960/35339 (25%)]\tLoss: 0.139865\n",
            "Train Epoch: 7 [9600/35339 (27%)]\tLoss: 0.077580\n",
            "Train Epoch: 7 [10240/35339 (29%)]\tLoss: 0.094033\n",
            "Train Epoch: 7 [10880/35339 (31%)]\tLoss: 0.264498\n",
            "Train Epoch: 7 [11520/35339 (33%)]\tLoss: 0.095952\n",
            "Train Epoch: 7 [12160/35339 (34%)]\tLoss: 0.068174\n",
            "Train Epoch: 7 [12800/35339 (36%)]\tLoss: 0.018766\n",
            "Train Epoch: 7 [13440/35339 (38%)]\tLoss: 0.055367\n",
            "Train Epoch: 7 [14080/35339 (40%)]\tLoss: 0.039100\n",
            "Train Epoch: 7 [14720/35339 (42%)]\tLoss: 0.003062\n",
            "Train Epoch: 7 [15360/35339 (43%)]\tLoss: 0.111336\n",
            "Train Epoch: 7 [16000/35339 (45%)]\tLoss: 0.059704\n",
            "Train Epoch: 7 [16640/35339 (47%)]\tLoss: 0.091806\n",
            "Train Epoch: 7 [17280/35339 (49%)]\tLoss: 0.047222\n",
            "Train Epoch: 7 [17920/35339 (51%)]\tLoss: 0.017487\n",
            "Train Epoch: 7 [18560/35339 (52%)]\tLoss: 0.022668\n",
            "Train Epoch: 7 [19200/35339 (54%)]\tLoss: 0.054254\n",
            "Train Epoch: 7 [19840/35339 (56%)]\tLoss: 0.290480\n",
            "Train Epoch: 7 [20480/35339 (58%)]\tLoss: 0.061858\n",
            "Train Epoch: 7 [21120/35339 (60%)]\tLoss: 0.027747\n",
            "Train Epoch: 7 [21760/35339 (61%)]\tLoss: 0.032236\n",
            "Train Epoch: 7 [22400/35339 (63%)]\tLoss: 0.140693\n",
            "Train Epoch: 7 [23040/35339 (65%)]\tLoss: 0.033054\n",
            "Train Epoch: 7 [23680/35339 (67%)]\tLoss: 0.175065\n",
            "Train Epoch: 7 [24320/35339 (69%)]\tLoss: 0.044919\n",
            "Train Epoch: 7 [24960/35339 (71%)]\tLoss: 0.005654\n",
            "Train Epoch: 7 [25600/35339 (72%)]\tLoss: 0.015393\n",
            "Train Epoch: 7 [26240/35339 (74%)]\tLoss: 0.150609\n",
            "Train Epoch: 7 [26880/35339 (76%)]\tLoss: 0.082957\n",
            "Train Epoch: 7 [27520/35339 (78%)]\tLoss: 0.022059\n",
            "Train Epoch: 7 [28160/35339 (80%)]\tLoss: 0.123130\n",
            "Train Epoch: 7 [28800/35339 (81%)]\tLoss: 0.025731\n",
            "Train Epoch: 7 [29440/35339 (83%)]\tLoss: 0.083094\n",
            "Train Epoch: 7 [30080/35339 (85%)]\tLoss: 0.070669\n",
            "Train Epoch: 7 [30720/35339 (87%)]\tLoss: 0.068129\n",
            "Train Epoch: 7 [31360/35339 (89%)]\tLoss: 0.077375\n",
            "Train Epoch: 7 [32000/35339 (90%)]\tLoss: 0.033830\n",
            "Train Epoch: 7 [32640/35339 (92%)]\tLoss: 0.038684\n",
            "Train Epoch: 7 [33280/35339 (94%)]\tLoss: 0.048507\n",
            "Train Epoch: 7 [33920/35339 (96%)]\tLoss: 0.019811\n",
            "Train Epoch: 7 [34560/35339 (98%)]\tLoss: 0.017443\n",
            "Train Epoch: 7 [35200/35339 (99%)]\tLoss: 0.018340\n",
            "\n",
            "Validation set: Average loss: 0.1318, Accuracy: 3712/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_7.pth.\n",
            "Train Epoch: 8 [0/35339 (0%)]\tLoss: 0.051533\n",
            "Train Epoch: 8 [640/35339 (2%)]\tLoss: 0.018019\n",
            "Train Epoch: 8 [1280/35339 (4%)]\tLoss: 0.020170\n",
            "Train Epoch: 8 [1920/35339 (5%)]\tLoss: 0.003815\n",
            "Train Epoch: 8 [2560/35339 (7%)]\tLoss: 0.032181\n",
            "Train Epoch: 8 [3200/35339 (9%)]\tLoss: 0.075098\n",
            "Train Epoch: 8 [3840/35339 (11%)]\tLoss: 0.024240\n",
            "Train Epoch: 8 [4480/35339 (13%)]\tLoss: 0.009486\n",
            "Train Epoch: 8 [5120/35339 (14%)]\tLoss: 0.100182\n",
            "Train Epoch: 8 [5760/35339 (16%)]\tLoss: 0.057861\n",
            "Train Epoch: 8 [6400/35339 (18%)]\tLoss: 0.066870\n",
            "Train Epoch: 8 [7040/35339 (20%)]\tLoss: 0.002166\n",
            "Train Epoch: 8 [7680/35339 (22%)]\tLoss: 0.006527\n",
            "Train Epoch: 8 [8320/35339 (24%)]\tLoss: 0.092889\n",
            "Train Epoch: 8 [8960/35339 (25%)]\tLoss: 0.125626\n",
            "Train Epoch: 8 [9600/35339 (27%)]\tLoss: 0.025235\n",
            "Train Epoch: 8 [10240/35339 (29%)]\tLoss: 0.243165\n",
            "Train Epoch: 8 [10880/35339 (31%)]\tLoss: 0.064003\n",
            "Train Epoch: 8 [11520/35339 (33%)]\tLoss: 0.323494\n",
            "Train Epoch: 8 [12160/35339 (34%)]\tLoss: 0.012545\n",
            "Train Epoch: 8 [12800/35339 (36%)]\tLoss: 0.076695\n",
            "Train Epoch: 8 [13440/35339 (38%)]\tLoss: 0.023476\n",
            "Train Epoch: 8 [14080/35339 (40%)]\tLoss: 0.025243\n",
            "Train Epoch: 8 [14720/35339 (42%)]\tLoss: 0.020083\n",
            "Train Epoch: 8 [15360/35339 (43%)]\tLoss: 0.043256\n",
            "Train Epoch: 8 [16000/35339 (45%)]\tLoss: 0.007730\n",
            "Train Epoch: 8 [16640/35339 (47%)]\tLoss: 0.051310\n",
            "Train Epoch: 8 [17280/35339 (49%)]\tLoss: 0.221949\n",
            "Train Epoch: 8 [17920/35339 (51%)]\tLoss: 0.021694\n",
            "Train Epoch: 8 [18560/35339 (52%)]\tLoss: 0.062857\n",
            "Train Epoch: 8 [19200/35339 (54%)]\tLoss: 0.033460\n",
            "Train Epoch: 8 [19840/35339 (56%)]\tLoss: 0.017524\n",
            "Train Epoch: 8 [20480/35339 (58%)]\tLoss: 0.039609\n",
            "Train Epoch: 8 [21120/35339 (60%)]\tLoss: 0.046242\n",
            "Train Epoch: 8 [21760/35339 (61%)]\tLoss: 0.013644\n",
            "Train Epoch: 8 [22400/35339 (63%)]\tLoss: 0.155881\n",
            "Train Epoch: 8 [23040/35339 (65%)]\tLoss: 0.086714\n",
            "Train Epoch: 8 [23680/35339 (67%)]\tLoss: 0.021814\n",
            "Train Epoch: 8 [24320/35339 (69%)]\tLoss: 0.010038\n",
            "Train Epoch: 8 [24960/35339 (71%)]\tLoss: 0.140011\n",
            "Train Epoch: 8 [25600/35339 (72%)]\tLoss: 0.017439\n",
            "Train Epoch: 8 [26240/35339 (74%)]\tLoss: 0.066278\n",
            "Train Epoch: 8 [26880/35339 (76%)]\tLoss: 0.030705\n",
            "Train Epoch: 8 [27520/35339 (78%)]\tLoss: 0.023802\n",
            "Train Epoch: 8 [28160/35339 (80%)]\tLoss: 0.028441\n",
            "Train Epoch: 8 [28800/35339 (81%)]\tLoss: 0.109279\n",
            "Train Epoch: 8 [29440/35339 (83%)]\tLoss: 0.139103\n",
            "Train Epoch: 8 [30080/35339 (85%)]\tLoss: 0.135837\n",
            "Train Epoch: 8 [30720/35339 (87%)]\tLoss: 0.079211\n",
            "Train Epoch: 8 [31360/35339 (89%)]\tLoss: 0.043562\n",
            "Train Epoch: 8 [32000/35339 (90%)]\tLoss: 0.023112\n",
            "Train Epoch: 8 [32640/35339 (92%)]\tLoss: 0.036572\n",
            "Train Epoch: 8 [33280/35339 (94%)]\tLoss: 0.055709\n",
            "Train Epoch: 8 [33920/35339 (96%)]\tLoss: 0.055215\n",
            "Train Epoch: 8 [34560/35339 (98%)]\tLoss: 0.077604\n",
            "Train Epoch: 8 [35200/35339 (99%)]\tLoss: 0.011215\n",
            "\n",
            "Validation set: Average loss: 0.1088, Accuracy: 3755/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_8.pth.\n",
            "\n",
            "Most accurate epoch so far: 8\n",
            "Train Epoch: 9 [0/35339 (0%)]\tLoss: 0.171738\n",
            "Train Epoch: 9 [640/35339 (2%)]\tLoss: 0.040235\n",
            "Train Epoch: 9 [1280/35339 (4%)]\tLoss: 0.101108\n",
            "Train Epoch: 9 [1920/35339 (5%)]\tLoss: 0.015145\n",
            "Train Epoch: 9 [2560/35339 (7%)]\tLoss: 0.017231\n",
            "Train Epoch: 9 [3200/35339 (9%)]\tLoss: 0.023246\n",
            "Train Epoch: 9 [3840/35339 (11%)]\tLoss: 0.091731\n",
            "Train Epoch: 9 [4480/35339 (13%)]\tLoss: 0.063795\n",
            "Train Epoch: 9 [5120/35339 (14%)]\tLoss: 0.023583\n",
            "Train Epoch: 9 [5760/35339 (16%)]\tLoss: 0.019581\n",
            "Train Epoch: 9 [6400/35339 (18%)]\tLoss: 0.004180\n",
            "Train Epoch: 9 [7040/35339 (20%)]\tLoss: 0.067813\n",
            "Train Epoch: 9 [7680/35339 (22%)]\tLoss: 0.038932\n",
            "Train Epoch: 9 [8320/35339 (24%)]\tLoss: 0.016953\n",
            "Train Epoch: 9 [8960/35339 (25%)]\tLoss: 0.020413\n",
            "Train Epoch: 9 [9600/35339 (27%)]\tLoss: 0.051334\n",
            "Train Epoch: 9 [10240/35339 (29%)]\tLoss: 0.002547\n",
            "Train Epoch: 9 [10880/35339 (31%)]\tLoss: 0.100487\n",
            "Train Epoch: 9 [11520/35339 (33%)]\tLoss: 0.168601\n",
            "Train Epoch: 9 [12160/35339 (34%)]\tLoss: 0.005269\n",
            "Train Epoch: 9 [12800/35339 (36%)]\tLoss: 0.019298\n",
            "Train Epoch: 9 [13440/35339 (38%)]\tLoss: 0.007459\n",
            "Train Epoch: 9 [14080/35339 (40%)]\tLoss: 0.000856\n",
            "Train Epoch: 9 [14720/35339 (42%)]\tLoss: 0.060382\n",
            "Train Epoch: 9 [15360/35339 (43%)]\tLoss: 0.053386\n",
            "Train Epoch: 9 [16000/35339 (45%)]\tLoss: 0.085032\n",
            "Train Epoch: 9 [16640/35339 (47%)]\tLoss: 0.131398\n",
            "Train Epoch: 9 [17280/35339 (49%)]\tLoss: 0.055405\n",
            "Train Epoch: 9 [17920/35339 (51%)]\tLoss: 0.019117\n",
            "Train Epoch: 9 [18560/35339 (52%)]\tLoss: 0.093697\n",
            "Train Epoch: 9 [19200/35339 (54%)]\tLoss: 0.032458\n",
            "Train Epoch: 9 [19840/35339 (56%)]\tLoss: 0.112400\n",
            "Train Epoch: 9 [20480/35339 (58%)]\tLoss: 0.028299\n",
            "Train Epoch: 9 [21120/35339 (60%)]\tLoss: 0.013620\n",
            "Train Epoch: 9 [21760/35339 (61%)]\tLoss: 0.007044\n",
            "Train Epoch: 9 [22400/35339 (63%)]\tLoss: 0.107110\n",
            "Train Epoch: 9 [23040/35339 (65%)]\tLoss: 0.005535\n",
            "Train Epoch: 9 [23680/35339 (67%)]\tLoss: 0.041188\n",
            "Train Epoch: 9 [24320/35339 (69%)]\tLoss: 0.022467\n",
            "Train Epoch: 9 [24960/35339 (71%)]\tLoss: 0.042788\n",
            "Train Epoch: 9 [25600/35339 (72%)]\tLoss: 0.015582\n",
            "Train Epoch: 9 [26240/35339 (74%)]\tLoss: 0.062425\n",
            "Train Epoch: 9 [26880/35339 (76%)]\tLoss: 0.027571\n",
            "Train Epoch: 9 [27520/35339 (78%)]\tLoss: 0.022238\n",
            "Train Epoch: 9 [28160/35339 (80%)]\tLoss: 0.026252\n",
            "Train Epoch: 9 [28800/35339 (81%)]\tLoss: 0.069069\n",
            "Train Epoch: 9 [29440/35339 (83%)]\tLoss: 0.008774\n",
            "Train Epoch: 9 [30080/35339 (85%)]\tLoss: 0.034127\n",
            "Train Epoch: 9 [30720/35339 (87%)]\tLoss: 0.026203\n",
            "Train Epoch: 9 [31360/35339 (89%)]\tLoss: 0.076203\n",
            "Train Epoch: 9 [32000/35339 (90%)]\tLoss: 0.023127\n",
            "Train Epoch: 9 [32640/35339 (92%)]\tLoss: 0.097772\n",
            "Train Epoch: 9 [33280/35339 (94%)]\tLoss: 0.104517\n",
            "Train Epoch: 9 [33920/35339 (96%)]\tLoss: 0.060076\n",
            "Train Epoch: 9 [34560/35339 (98%)]\tLoss: 0.083087\n",
            "Train Epoch: 9 [35200/35339 (99%)]\tLoss: 0.031576\n",
            "\n",
            "Validation set: Average loss: 0.1110, Accuracy: 3766/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_9.pth.\n",
            "\n",
            "Most accurate epoch so far: 9\n",
            "Train Epoch: 10 [0/35339 (0%)]\tLoss: 0.073673\n",
            "Train Epoch: 10 [640/35339 (2%)]\tLoss: 0.027643\n",
            "Train Epoch: 10 [1280/35339 (4%)]\tLoss: 0.065612\n",
            "Train Epoch: 10 [1920/35339 (5%)]\tLoss: 0.065710\n",
            "Train Epoch: 10 [2560/35339 (7%)]\tLoss: 0.053126\n",
            "Train Epoch: 10 [3200/35339 (9%)]\tLoss: 0.023422\n",
            "Train Epoch: 10 [3840/35339 (11%)]\tLoss: 0.005227\n",
            "Train Epoch: 10 [4480/35339 (13%)]\tLoss: 0.084536\n",
            "Train Epoch: 10 [5120/35339 (14%)]\tLoss: 0.045861\n",
            "Train Epoch: 10 [5760/35339 (16%)]\tLoss: 0.053870\n",
            "Train Epoch: 10 [6400/35339 (18%)]\tLoss: 0.045907\n",
            "Train Epoch: 10 [7040/35339 (20%)]\tLoss: 0.014476\n",
            "Train Epoch: 10 [7680/35339 (22%)]\tLoss: 0.018298\n",
            "Train Epoch: 10 [8320/35339 (24%)]\tLoss: 0.021268\n",
            "Train Epoch: 10 [8960/35339 (25%)]\tLoss: 0.005895\n",
            "Train Epoch: 10 [9600/35339 (27%)]\tLoss: 0.003363\n",
            "Train Epoch: 10 [10240/35339 (29%)]\tLoss: 0.007753\n",
            "Train Epoch: 10 [10880/35339 (31%)]\tLoss: 0.127981\n",
            "Train Epoch: 10 [11520/35339 (33%)]\tLoss: 0.048758\n",
            "Train Epoch: 10 [12160/35339 (34%)]\tLoss: 0.009252\n",
            "Train Epoch: 10 [12800/35339 (36%)]\tLoss: 0.028516\n",
            "Train Epoch: 10 [13440/35339 (38%)]\tLoss: 0.005869\n",
            "Train Epoch: 10 [14080/35339 (40%)]\tLoss: 0.039753\n",
            "Train Epoch: 10 [14720/35339 (42%)]\tLoss: 0.077476\n",
            "Train Epoch: 10 [15360/35339 (43%)]\tLoss: 0.067619\n",
            "Train Epoch: 10 [16000/35339 (45%)]\tLoss: 0.013162\n",
            "Train Epoch: 10 [16640/35339 (47%)]\tLoss: 0.054150\n",
            "Train Epoch: 10 [17280/35339 (49%)]\tLoss: 0.010515\n",
            "Train Epoch: 10 [17920/35339 (51%)]\tLoss: 0.094200\n",
            "Train Epoch: 10 [18560/35339 (52%)]\tLoss: 0.045340\n",
            "Train Epoch: 10 [19200/35339 (54%)]\tLoss: 0.013636\n",
            "Train Epoch: 10 [19840/35339 (56%)]\tLoss: 0.046402\n",
            "Train Epoch: 10 [20480/35339 (58%)]\tLoss: 0.035270\n",
            "Train Epoch: 10 [21120/35339 (60%)]\tLoss: 0.400413\n",
            "Train Epoch: 10 [21760/35339 (61%)]\tLoss: 0.054338\n",
            "Train Epoch: 10 [22400/35339 (63%)]\tLoss: 0.033841\n",
            "Train Epoch: 10 [23040/35339 (65%)]\tLoss: 0.084187\n",
            "Train Epoch: 10 [23680/35339 (67%)]\tLoss: 0.047001\n",
            "Train Epoch: 10 [24320/35339 (69%)]\tLoss: 0.097344\n",
            "Train Epoch: 10 [24960/35339 (71%)]\tLoss: 0.019386\n",
            "Train Epoch: 10 [25600/35339 (72%)]\tLoss: 0.043913\n",
            "Train Epoch: 10 [26240/35339 (74%)]\tLoss: 0.008482\n",
            "Train Epoch: 10 [26880/35339 (76%)]\tLoss: 0.047134\n",
            "Train Epoch: 10 [27520/35339 (78%)]\tLoss: 0.028708\n",
            "Train Epoch: 10 [28160/35339 (80%)]\tLoss: 0.002630\n",
            "Train Epoch: 10 [28800/35339 (81%)]\tLoss: 0.135452\n",
            "Train Epoch: 10 [29440/35339 (83%)]\tLoss: 0.022840\n",
            "Train Epoch: 10 [30080/35339 (85%)]\tLoss: 0.035058\n",
            "Train Epoch: 10 [30720/35339 (87%)]\tLoss: 0.147965\n",
            "Train Epoch: 10 [31360/35339 (89%)]\tLoss: 0.070180\n",
            "Train Epoch: 10 [32000/35339 (90%)]\tLoss: 0.032935\n",
            "Train Epoch: 10 [32640/35339 (92%)]\tLoss: 0.041693\n",
            "Train Epoch: 10 [33280/35339 (94%)]\tLoss: 0.046385\n",
            "Train Epoch: 10 [33920/35339 (96%)]\tLoss: 0.098222\n",
            "Train Epoch: 10 [34560/35339 (98%)]\tLoss: 0.012777\n",
            "Train Epoch: 10 [35200/35339 (99%)]\tLoss: 0.056488\n",
            "\n",
            "Validation set: Average loss: 0.1054, Accuracy: 3750/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_10.pth.\n",
            "Train Epoch: 11 [0/35339 (0%)]\tLoss: 0.075049\n",
            "Train Epoch: 11 [640/35339 (2%)]\tLoss: 0.013959\n",
            "Train Epoch: 11 [1280/35339 (4%)]\tLoss: 0.025762\n",
            "Train Epoch: 11 [1920/35339 (5%)]\tLoss: 0.003870\n",
            "Train Epoch: 11 [2560/35339 (7%)]\tLoss: 0.051004\n",
            "Train Epoch: 11 [3200/35339 (9%)]\tLoss: 0.016983\n",
            "Train Epoch: 11 [3840/35339 (11%)]\tLoss: 0.039898\n",
            "Train Epoch: 11 [4480/35339 (13%)]\tLoss: 0.022464\n",
            "Train Epoch: 11 [5120/35339 (14%)]\tLoss: 0.018762\n",
            "Train Epoch: 11 [5760/35339 (16%)]\tLoss: 0.038194\n",
            "Train Epoch: 11 [6400/35339 (18%)]\tLoss: 0.068237\n",
            "Train Epoch: 11 [7040/35339 (20%)]\tLoss: 0.008087\n",
            "Train Epoch: 11 [7680/35339 (22%)]\tLoss: 0.095496\n",
            "Train Epoch: 11 [8320/35339 (24%)]\tLoss: 0.005199\n",
            "Train Epoch: 11 [8960/35339 (25%)]\tLoss: 0.028152\n",
            "Train Epoch: 11 [9600/35339 (27%)]\tLoss: 0.010666\n",
            "Train Epoch: 11 [10240/35339 (29%)]\tLoss: 0.015298\n",
            "Train Epoch: 11 [10880/35339 (31%)]\tLoss: 0.066085\n",
            "Train Epoch: 11 [11520/35339 (33%)]\tLoss: 0.066742\n",
            "Train Epoch: 11 [12160/35339 (34%)]\tLoss: 0.025465\n",
            "Train Epoch: 11 [12800/35339 (36%)]\tLoss: 0.039435\n",
            "Train Epoch: 11 [13440/35339 (38%)]\tLoss: 0.029508\n",
            "Train Epoch: 11 [14080/35339 (40%)]\tLoss: 0.048350\n",
            "Train Epoch: 11 [14720/35339 (42%)]\tLoss: 0.110942\n",
            "Train Epoch: 11 [15360/35339 (43%)]\tLoss: 0.014156\n",
            "Train Epoch: 11 [16000/35339 (45%)]\tLoss: 0.012980\n",
            "Train Epoch: 11 [16640/35339 (47%)]\tLoss: 0.065176\n",
            "Train Epoch: 11 [17280/35339 (49%)]\tLoss: 0.011694\n",
            "Train Epoch: 11 [17920/35339 (51%)]\tLoss: 0.035643\n",
            "Train Epoch: 11 [18560/35339 (52%)]\tLoss: 0.014931\n",
            "Train Epoch: 11 [19200/35339 (54%)]\tLoss: 0.045196\n",
            "Train Epoch: 11 [19840/35339 (56%)]\tLoss: 0.059718\n",
            "Train Epoch: 11 [20480/35339 (58%)]\tLoss: 0.015787\n",
            "Train Epoch: 11 [21120/35339 (60%)]\tLoss: 0.068736\n",
            "Train Epoch: 11 [21760/35339 (61%)]\tLoss: 0.071162\n",
            "Train Epoch: 11 [22400/35339 (63%)]\tLoss: 0.009166\n",
            "Train Epoch: 11 [23040/35339 (65%)]\tLoss: 0.144869\n",
            "Train Epoch: 11 [23680/35339 (67%)]\tLoss: 0.028943\n",
            "Train Epoch: 11 [24320/35339 (69%)]\tLoss: 0.003655\n",
            "Train Epoch: 11 [24960/35339 (71%)]\tLoss: 0.013937\n",
            "Train Epoch: 11 [25600/35339 (72%)]\tLoss: 0.063466\n",
            "Train Epoch: 11 [26240/35339 (74%)]\tLoss: 0.030965\n",
            "Train Epoch: 11 [26880/35339 (76%)]\tLoss: 0.008470\n",
            "Train Epoch: 11 [27520/35339 (78%)]\tLoss: 0.065120\n",
            "Train Epoch: 11 [28160/35339 (80%)]\tLoss: 0.026217\n",
            "Train Epoch: 11 [28800/35339 (81%)]\tLoss: 0.002503\n",
            "Train Epoch: 11 [29440/35339 (83%)]\tLoss: 0.002867\n",
            "Train Epoch: 11 [30080/35339 (85%)]\tLoss: 0.001648\n",
            "Train Epoch: 11 [30720/35339 (87%)]\tLoss: 0.008279\n",
            "Train Epoch: 11 [31360/35339 (89%)]\tLoss: 0.079320\n",
            "Train Epoch: 11 [32000/35339 (90%)]\tLoss: 0.048332\n",
            "Train Epoch: 11 [32640/35339 (92%)]\tLoss: 0.026607\n",
            "Train Epoch: 11 [33280/35339 (94%)]\tLoss: 0.062746\n",
            "Train Epoch: 11 [33920/35339 (96%)]\tLoss: 0.050741\n",
            "Train Epoch: 11 [34560/35339 (98%)]\tLoss: 0.003296\n",
            "Train Epoch: 11 [35200/35339 (99%)]\tLoss: 0.135475\n",
            "\n",
            "Validation set: Average loss: 0.1142, Accuracy: 3729/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_11.pth.\n",
            "Train Epoch: 12 [0/35339 (0%)]\tLoss: 0.029565\n",
            "Train Epoch: 12 [640/35339 (2%)]\tLoss: 0.011148\n",
            "Train Epoch: 12 [1280/35339 (4%)]\tLoss: 0.034082\n",
            "Train Epoch: 12 [1920/35339 (5%)]\tLoss: 0.049704\n",
            "Train Epoch: 12 [2560/35339 (7%)]\tLoss: 0.017461\n",
            "Train Epoch: 12 [3200/35339 (9%)]\tLoss: 0.048763\n",
            "Train Epoch: 12 [3840/35339 (11%)]\tLoss: 0.019194\n",
            "Train Epoch: 12 [4480/35339 (13%)]\tLoss: 0.017455\n",
            "Train Epoch: 12 [5120/35339 (14%)]\tLoss: 0.008640\n",
            "Train Epoch: 12 [5760/35339 (16%)]\tLoss: 0.004611\n",
            "Train Epoch: 12 [6400/35339 (18%)]\tLoss: 0.048443\n",
            "Train Epoch: 12 [7040/35339 (20%)]\tLoss: 0.004935\n",
            "Train Epoch: 12 [7680/35339 (22%)]\tLoss: 0.028065\n",
            "Train Epoch: 12 [8320/35339 (24%)]\tLoss: 0.006665\n",
            "Train Epoch: 12 [8960/35339 (25%)]\tLoss: 0.062726\n",
            "Train Epoch: 12 [9600/35339 (27%)]\tLoss: 0.105007\n",
            "Train Epoch: 12 [10240/35339 (29%)]\tLoss: 0.030851\n",
            "Train Epoch: 12 [10880/35339 (31%)]\tLoss: 0.031144\n",
            "Train Epoch: 12 [11520/35339 (33%)]\tLoss: 0.067559\n",
            "Train Epoch: 12 [12160/35339 (34%)]\tLoss: 0.062070\n",
            "Train Epoch: 12 [12800/35339 (36%)]\tLoss: 0.069778\n",
            "Train Epoch: 12 [13440/35339 (38%)]\tLoss: 0.032896\n",
            "Train Epoch: 12 [14080/35339 (40%)]\tLoss: 0.012083\n",
            "Train Epoch: 12 [14720/35339 (42%)]\tLoss: 0.012138\n",
            "Train Epoch: 12 [15360/35339 (43%)]\tLoss: 0.065048\n",
            "Train Epoch: 12 [16000/35339 (45%)]\tLoss: 0.019984\n",
            "Train Epoch: 12 [16640/35339 (47%)]\tLoss: 0.024970\n",
            "Train Epoch: 12 [17280/35339 (49%)]\tLoss: 0.059233\n",
            "Train Epoch: 12 [17920/35339 (51%)]\tLoss: 0.055950\n",
            "Train Epoch: 12 [18560/35339 (52%)]\tLoss: 0.011946\n",
            "Train Epoch: 12 [19200/35339 (54%)]\tLoss: 0.003150\n",
            "Train Epoch: 12 [19840/35339 (56%)]\tLoss: 0.008413\n",
            "Train Epoch: 12 [20480/35339 (58%)]\tLoss: 0.005915\n",
            "Train Epoch: 12 [21120/35339 (60%)]\tLoss: 0.030287\n",
            "Train Epoch: 12 [21760/35339 (61%)]\tLoss: 0.008990\n",
            "Train Epoch: 12 [22400/35339 (63%)]\tLoss: 0.065066\n",
            "Train Epoch: 12 [23040/35339 (65%)]\tLoss: 0.061750\n",
            "Train Epoch: 12 [23680/35339 (67%)]\tLoss: 0.052255\n",
            "Train Epoch: 12 [24320/35339 (69%)]\tLoss: 0.007419\n",
            "Train Epoch: 12 [24960/35339 (71%)]\tLoss: 0.003473\n",
            "Train Epoch: 12 [25600/35339 (72%)]\tLoss: 0.069222\n",
            "Train Epoch: 12 [26240/35339 (74%)]\tLoss: 0.041519\n",
            "Train Epoch: 12 [26880/35339 (76%)]\tLoss: 0.048834\n",
            "Train Epoch: 12 [27520/35339 (78%)]\tLoss: 0.009721\n",
            "Train Epoch: 12 [28160/35339 (80%)]\tLoss: 0.070418\n",
            "Train Epoch: 12 [28800/35339 (81%)]\tLoss: 0.044568\n",
            "Train Epoch: 12 [29440/35339 (83%)]\tLoss: 0.031040\n",
            "Train Epoch: 12 [30080/35339 (85%)]\tLoss: 0.017166\n",
            "Train Epoch: 12 [30720/35339 (87%)]\tLoss: 0.001362\n",
            "Train Epoch: 12 [31360/35339 (89%)]\tLoss: 0.153065\n",
            "Train Epoch: 12 [32000/35339 (90%)]\tLoss: 0.088973\n",
            "Train Epoch: 12 [32640/35339 (92%)]\tLoss: 0.013967\n",
            "Train Epoch: 12 [33280/35339 (94%)]\tLoss: 0.061879\n",
            "Train Epoch: 12 [33920/35339 (96%)]\tLoss: 0.001569\n",
            "Train Epoch: 12 [34560/35339 (98%)]\tLoss: 0.002122\n",
            "Train Epoch: 12 [35200/35339 (99%)]\tLoss: 0.041502\n",
            "\n",
            "Validation set: Average loss: 0.1299, Accuracy: 3741/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_12.pth.\n",
            "Train Epoch: 13 [0/35339 (0%)]\tLoss: 0.000260\n",
            "Train Epoch: 13 [640/35339 (2%)]\tLoss: 0.064549\n",
            "Train Epoch: 13 [1280/35339 (4%)]\tLoss: 0.067484\n",
            "Train Epoch: 13 [1920/35339 (5%)]\tLoss: 0.013160\n",
            "Train Epoch: 13 [2560/35339 (7%)]\tLoss: 0.004787\n",
            "Train Epoch: 13 [3200/35339 (9%)]\tLoss: 0.016272\n",
            "Train Epoch: 13 [3840/35339 (11%)]\tLoss: 0.004074\n",
            "Train Epoch: 13 [4480/35339 (13%)]\tLoss: 0.028232\n",
            "Train Epoch: 13 [5120/35339 (14%)]\tLoss: 0.023524\n",
            "Train Epoch: 13 [5760/35339 (16%)]\tLoss: 0.011555\n",
            "Train Epoch: 13 [6400/35339 (18%)]\tLoss: 0.096667\n",
            "Train Epoch: 13 [7040/35339 (20%)]\tLoss: 0.070770\n",
            "Train Epoch: 13 [7680/35339 (22%)]\tLoss: 0.066362\n",
            "Train Epoch: 13 [8320/35339 (24%)]\tLoss: 0.014432\n",
            "Train Epoch: 13 [8960/35339 (25%)]\tLoss: 0.124650\n",
            "Train Epoch: 13 [9600/35339 (27%)]\tLoss: 0.059536\n",
            "Train Epoch: 13 [10240/35339 (29%)]\tLoss: 0.001804\n",
            "Train Epoch: 13 [10880/35339 (31%)]\tLoss: 0.015609\n",
            "Train Epoch: 13 [11520/35339 (33%)]\tLoss: 0.077755\n",
            "Train Epoch: 13 [12160/35339 (34%)]\tLoss: 0.015496\n",
            "Train Epoch: 13 [12800/35339 (36%)]\tLoss: 0.012148\n",
            "Train Epoch: 13 [13440/35339 (38%)]\tLoss: 0.035862\n",
            "Train Epoch: 13 [14080/35339 (40%)]\tLoss: 0.034075\n",
            "Train Epoch: 13 [14720/35339 (42%)]\tLoss: 0.004125\n",
            "Train Epoch: 13 [15360/35339 (43%)]\tLoss: 0.050816\n",
            "Train Epoch: 13 [16000/35339 (45%)]\tLoss: 0.018867\n",
            "Train Epoch: 13 [16640/35339 (47%)]\tLoss: 0.050455\n",
            "Train Epoch: 13 [17280/35339 (49%)]\tLoss: 0.009501\n",
            "Train Epoch: 13 [17920/35339 (51%)]\tLoss: 0.041064\n",
            "Train Epoch: 13 [18560/35339 (52%)]\tLoss: 0.001159\n",
            "Train Epoch: 13 [19200/35339 (54%)]\tLoss: 0.003895\n",
            "Train Epoch: 13 [19840/35339 (56%)]\tLoss: 0.092349\n",
            "Train Epoch: 13 [20480/35339 (58%)]\tLoss: 0.042947\n",
            "Train Epoch: 13 [21120/35339 (60%)]\tLoss: 0.078824\n",
            "Train Epoch: 13 [21760/35339 (61%)]\tLoss: 0.004287\n",
            "Train Epoch: 13 [22400/35339 (63%)]\tLoss: 0.207365\n",
            "Train Epoch: 13 [23040/35339 (65%)]\tLoss: 0.060065\n",
            "Train Epoch: 13 [23680/35339 (67%)]\tLoss: 0.033672\n",
            "Train Epoch: 13 [24320/35339 (69%)]\tLoss: 0.041295\n",
            "Train Epoch: 13 [24960/35339 (71%)]\tLoss: 0.061574\n",
            "Train Epoch: 13 [25600/35339 (72%)]\tLoss: 0.102880\n",
            "Train Epoch: 13 [26240/35339 (74%)]\tLoss: 0.113978\n",
            "Train Epoch: 13 [26880/35339 (76%)]\tLoss: 0.001546\n",
            "Train Epoch: 13 [27520/35339 (78%)]\tLoss: 0.050594\n",
            "Train Epoch: 13 [28160/35339 (80%)]\tLoss: 0.095680\n",
            "Train Epoch: 13 [28800/35339 (81%)]\tLoss: 0.029348\n",
            "Train Epoch: 13 [29440/35339 (83%)]\tLoss: 0.032124\n",
            "Train Epoch: 13 [30080/35339 (85%)]\tLoss: 0.000309\n",
            "Train Epoch: 13 [30720/35339 (87%)]\tLoss: 0.050773\n",
            "Train Epoch: 13 [31360/35339 (89%)]\tLoss: 0.052193\n",
            "Train Epoch: 13 [32000/35339 (90%)]\tLoss: 0.027573\n",
            "Train Epoch: 13 [32640/35339 (92%)]\tLoss: 0.035805\n",
            "Train Epoch: 13 [33280/35339 (94%)]\tLoss: 0.058314\n",
            "Train Epoch: 13 [33920/35339 (96%)]\tLoss: 0.020678\n",
            "Train Epoch: 13 [34560/35339 (98%)]\tLoss: 0.002663\n",
            "Train Epoch: 13 [35200/35339 (99%)]\tLoss: 0.033057\n",
            "\n",
            "Validation set: Average loss: 0.1392, Accuracy: 3742/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_13.pth.\n",
            "Train Epoch: 14 [0/35339 (0%)]\tLoss: 0.040009\n",
            "Train Epoch: 14 [640/35339 (2%)]\tLoss: 0.080886\n",
            "Train Epoch: 14 [1280/35339 (4%)]\tLoss: 0.019217\n",
            "Train Epoch: 14 [1920/35339 (5%)]\tLoss: 0.027077\n",
            "Train Epoch: 14 [2560/35339 (7%)]\tLoss: 0.169207\n",
            "Train Epoch: 14 [3200/35339 (9%)]\tLoss: 0.023581\n",
            "Train Epoch: 14 [3840/35339 (11%)]\tLoss: 0.004552\n",
            "Train Epoch: 14 [4480/35339 (13%)]\tLoss: 0.023418\n",
            "Train Epoch: 14 [5120/35339 (14%)]\tLoss: 0.038206\n",
            "Train Epoch: 14 [5760/35339 (16%)]\tLoss: 0.013486\n",
            "Train Epoch: 14 [6400/35339 (18%)]\tLoss: 0.077177\n",
            "Train Epoch: 14 [7040/35339 (20%)]\tLoss: 0.002565\n",
            "Train Epoch: 14 [7680/35339 (22%)]\tLoss: 0.000891\n",
            "Train Epoch: 14 [8320/35339 (24%)]\tLoss: 0.005628\n",
            "Train Epoch: 14 [8960/35339 (25%)]\tLoss: 0.008369\n",
            "Train Epoch: 14 [9600/35339 (27%)]\tLoss: 0.036667\n",
            "Train Epoch: 14 [10240/35339 (29%)]\tLoss: 0.000643\n",
            "Train Epoch: 14 [10880/35339 (31%)]\tLoss: 0.067566\n",
            "Train Epoch: 14 [11520/35339 (33%)]\tLoss: 0.084496\n",
            "Train Epoch: 14 [12160/35339 (34%)]\tLoss: 0.091596\n",
            "Train Epoch: 14 [12800/35339 (36%)]\tLoss: 0.044257\n",
            "Train Epoch: 14 [13440/35339 (38%)]\tLoss: 0.053414\n",
            "Train Epoch: 14 [14080/35339 (40%)]\tLoss: 0.037608\n",
            "Train Epoch: 14 [14720/35339 (42%)]\tLoss: 0.005789\n",
            "Train Epoch: 14 [15360/35339 (43%)]\tLoss: 0.008895\n",
            "Train Epoch: 14 [16000/35339 (45%)]\tLoss: 0.009833\n",
            "Train Epoch: 14 [16640/35339 (47%)]\tLoss: 0.046520\n",
            "Train Epoch: 14 [17280/35339 (49%)]\tLoss: 0.042258\n",
            "Train Epoch: 14 [17920/35339 (51%)]\tLoss: 0.024966\n",
            "Train Epoch: 14 [18560/35339 (52%)]\tLoss: 0.070365\n",
            "Train Epoch: 14 [19200/35339 (54%)]\tLoss: 0.078693\n",
            "Train Epoch: 14 [19840/35339 (56%)]\tLoss: 0.009495\n",
            "Train Epoch: 14 [20480/35339 (58%)]\tLoss: 0.013379\n",
            "Train Epoch: 14 [21120/35339 (60%)]\tLoss: 0.023397\n",
            "Train Epoch: 14 [21760/35339 (61%)]\tLoss: 0.038291\n",
            "Train Epoch: 14 [22400/35339 (63%)]\tLoss: 0.001732\n",
            "Train Epoch: 14 [23040/35339 (65%)]\tLoss: 0.029764\n",
            "Train Epoch: 14 [23680/35339 (67%)]\tLoss: 0.004933\n",
            "Train Epoch: 14 [24320/35339 (69%)]\tLoss: 0.001090\n",
            "Train Epoch: 14 [24960/35339 (71%)]\tLoss: 0.008311\n",
            "Train Epoch: 14 [25600/35339 (72%)]\tLoss: 0.001286\n",
            "Train Epoch: 14 [26240/35339 (74%)]\tLoss: 0.042550\n",
            "Train Epoch: 14 [26880/35339 (76%)]\tLoss: 0.055225\n",
            "Train Epoch: 14 [27520/35339 (78%)]\tLoss: 0.022808\n",
            "Train Epoch: 14 [28160/35339 (80%)]\tLoss: 0.066495\n",
            "Train Epoch: 14 [28800/35339 (81%)]\tLoss: 0.053898\n",
            "Train Epoch: 14 [29440/35339 (83%)]\tLoss: 0.044242\n",
            "Train Epoch: 14 [30080/35339 (85%)]\tLoss: 0.009348\n",
            "Train Epoch: 14 [30720/35339 (87%)]\tLoss: 0.060569\n",
            "Train Epoch: 14 [31360/35339 (89%)]\tLoss: 0.011890\n",
            "Train Epoch: 14 [32000/35339 (90%)]\tLoss: 0.104151\n",
            "Train Epoch: 14 [32640/35339 (92%)]\tLoss: 0.000896\n",
            "Train Epoch: 14 [33280/35339 (94%)]\tLoss: 0.062369\n",
            "Train Epoch: 14 [33920/35339 (96%)]\tLoss: 0.006037\n",
            "Train Epoch: 14 [34560/35339 (98%)]\tLoss: 0.006635\n",
            "Train Epoch: 14 [35200/35339 (99%)]\tLoss: 0.060403\n",
            "\n",
            "Validation set: Average loss: 0.1731, Accuracy: 3720/3870 (96%)\n",
            "\n",
            "\n",
            "Saved model to model_14.pth.\n",
            "Train Epoch: 15 [0/35339 (0%)]\tLoss: 0.101434\n",
            "Train Epoch: 15 [640/35339 (2%)]\tLoss: 0.122248\n",
            "Train Epoch: 15 [1280/35339 (4%)]\tLoss: 0.006191\n",
            "Train Epoch: 15 [1920/35339 (5%)]\tLoss: 0.052556\n",
            "Train Epoch: 15 [2560/35339 (7%)]\tLoss: 0.007062\n",
            "Train Epoch: 15 [3200/35339 (9%)]\tLoss: 0.006857\n",
            "Train Epoch: 15 [3840/35339 (11%)]\tLoss: 0.123137\n",
            "Train Epoch: 15 [4480/35339 (13%)]\tLoss: 0.050474\n",
            "Train Epoch: 15 [5120/35339 (14%)]\tLoss: 0.060765\n",
            "Train Epoch: 15 [5760/35339 (16%)]\tLoss: 0.004873\n",
            "Train Epoch: 15 [6400/35339 (18%)]\tLoss: 0.001938\n",
            "Train Epoch: 15 [7040/35339 (20%)]\tLoss: 0.019592\n",
            "Train Epoch: 15 [7680/35339 (22%)]\tLoss: 0.000345\n",
            "Train Epoch: 15 [8320/35339 (24%)]\tLoss: 0.004015\n",
            "Train Epoch: 15 [8960/35339 (25%)]\tLoss: 0.002828\n",
            "Train Epoch: 15 [9600/35339 (27%)]\tLoss: 0.030609\n",
            "Train Epoch: 15 [10240/35339 (29%)]\tLoss: 0.049175\n",
            "Train Epoch: 15 [10880/35339 (31%)]\tLoss: 0.039750\n",
            "Train Epoch: 15 [11520/35339 (33%)]\tLoss: 0.004730\n",
            "Train Epoch: 15 [12160/35339 (34%)]\tLoss: 0.087034\n",
            "Train Epoch: 15 [12800/35339 (36%)]\tLoss: 0.001431\n",
            "Train Epoch: 15 [13440/35339 (38%)]\tLoss: 0.003124\n",
            "Train Epoch: 15 [14080/35339 (40%)]\tLoss: 0.074293\n",
            "Train Epoch: 15 [14720/35339 (42%)]\tLoss: 0.002282\n",
            "Train Epoch: 15 [15360/35339 (43%)]\tLoss: 0.005457\n",
            "Train Epoch: 15 [16000/35339 (45%)]\tLoss: 0.007018\n",
            "Train Epoch: 15 [16640/35339 (47%)]\tLoss: 0.035903\n",
            "Train Epoch: 15 [17280/35339 (49%)]\tLoss: 0.002209\n",
            "Train Epoch: 15 [17920/35339 (51%)]\tLoss: 0.011884\n",
            "Train Epoch: 15 [18560/35339 (52%)]\tLoss: 0.082838\n",
            "Train Epoch: 15 [19200/35339 (54%)]\tLoss: 0.012546\n",
            "Train Epoch: 15 [19840/35339 (56%)]\tLoss: 0.024050\n",
            "Train Epoch: 15 [20480/35339 (58%)]\tLoss: 0.007565\n",
            "Train Epoch: 15 [21120/35339 (60%)]\tLoss: 0.085063\n",
            "Train Epoch: 15 [21760/35339 (61%)]\tLoss: 0.021392\n",
            "Train Epoch: 15 [22400/35339 (63%)]\tLoss: 0.003206\n",
            "Train Epoch: 15 [23040/35339 (65%)]\tLoss: 0.016244\n",
            "Train Epoch: 15 [23680/35339 (67%)]\tLoss: 0.032793\n",
            "Train Epoch: 15 [24320/35339 (69%)]\tLoss: 0.143539\n",
            "Train Epoch: 15 [24960/35339 (71%)]\tLoss: 0.046124\n",
            "Train Epoch: 15 [25600/35339 (72%)]\tLoss: 0.013463\n",
            "Train Epoch: 15 [26240/35339 (74%)]\tLoss: 0.073744\n",
            "Train Epoch: 15 [26880/35339 (76%)]\tLoss: 0.112529\n",
            "Train Epoch: 15 [27520/35339 (78%)]\tLoss: 0.004291\n",
            "Train Epoch: 15 [28160/35339 (80%)]\tLoss: 0.016798\n",
            "Train Epoch: 15 [28800/35339 (81%)]\tLoss: 0.034452\n",
            "Train Epoch: 15 [29440/35339 (83%)]\tLoss: 0.058249\n",
            "Train Epoch: 15 [30080/35339 (85%)]\tLoss: 0.018223\n",
            "Train Epoch: 15 [30720/35339 (87%)]\tLoss: 0.047428\n",
            "Train Epoch: 15 [31360/35339 (89%)]\tLoss: 0.065480\n",
            "Train Epoch: 15 [32000/35339 (90%)]\tLoss: 0.000330\n",
            "Train Epoch: 15 [32640/35339 (92%)]\tLoss: 0.045017\n",
            "Train Epoch: 15 [33280/35339 (94%)]\tLoss: 0.084123\n",
            "Train Epoch: 15 [33920/35339 (96%)]\tLoss: 0.009844\n",
            "Train Epoch: 15 [34560/35339 (98%)]\tLoss: 0.011536\n",
            "Train Epoch: 15 [35200/35339 (99%)]\tLoss: 0.029174\n",
            "\n",
            "Validation set: Average loss: 0.0839, Accuracy: 3782/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_15.pth.\n",
            "\n",
            "Most accurate epoch so far: 15\n",
            "Train Epoch: 16 [0/35339 (0%)]\tLoss: 0.010712\n",
            "Train Epoch: 16 [640/35339 (2%)]\tLoss: 0.053209\n",
            "Train Epoch: 16 [1280/35339 (4%)]\tLoss: 0.095049\n",
            "Train Epoch: 16 [1920/35339 (5%)]\tLoss: 0.027052\n",
            "Train Epoch: 16 [2560/35339 (7%)]\tLoss: 0.014539\n",
            "Train Epoch: 16 [3200/35339 (9%)]\tLoss: 0.031937\n",
            "Train Epoch: 16 [3840/35339 (11%)]\tLoss: 0.020622\n",
            "Train Epoch: 16 [4480/35339 (13%)]\tLoss: 0.011142\n",
            "Train Epoch: 16 [5120/35339 (14%)]\tLoss: 0.007155\n",
            "Train Epoch: 16 [5760/35339 (16%)]\tLoss: 0.000561\n",
            "Train Epoch: 16 [6400/35339 (18%)]\tLoss: 0.025252\n",
            "Train Epoch: 16 [7040/35339 (20%)]\tLoss: 0.034943\n",
            "Train Epoch: 16 [7680/35339 (22%)]\tLoss: 0.000490\n",
            "Train Epoch: 16 [8320/35339 (24%)]\tLoss: 0.033312\n",
            "Train Epoch: 16 [8960/35339 (25%)]\tLoss: 0.041736\n",
            "Train Epoch: 16 [9600/35339 (27%)]\tLoss: 0.035110\n",
            "Train Epoch: 16 [10240/35339 (29%)]\tLoss: 0.034493\n",
            "Train Epoch: 16 [10880/35339 (31%)]\tLoss: 0.051222\n",
            "Train Epoch: 16 [11520/35339 (33%)]\tLoss: 0.002822\n",
            "Train Epoch: 16 [12160/35339 (34%)]\tLoss: 0.101641\n",
            "Train Epoch: 16 [12800/35339 (36%)]\tLoss: 0.019436\n",
            "Train Epoch: 16 [13440/35339 (38%)]\tLoss: 0.022197\n",
            "Train Epoch: 16 [14080/35339 (40%)]\tLoss: 0.021231\n",
            "Train Epoch: 16 [14720/35339 (42%)]\tLoss: 0.004655\n",
            "Train Epoch: 16 [15360/35339 (43%)]\tLoss: 0.038490\n",
            "Train Epoch: 16 [16000/35339 (45%)]\tLoss: 0.001998\n",
            "Train Epoch: 16 [16640/35339 (47%)]\tLoss: 0.001428\n",
            "Train Epoch: 16 [17280/35339 (49%)]\tLoss: 0.004365\n",
            "Train Epoch: 16 [17920/35339 (51%)]\tLoss: 0.002246\n",
            "Train Epoch: 16 [18560/35339 (52%)]\tLoss: 0.118205\n",
            "Train Epoch: 16 [19200/35339 (54%)]\tLoss: 0.040467\n",
            "Train Epoch: 16 [19840/35339 (56%)]\tLoss: 0.026351\n",
            "Train Epoch: 16 [20480/35339 (58%)]\tLoss: 0.013100\n",
            "Train Epoch: 16 [21120/35339 (60%)]\tLoss: 0.023107\n",
            "Train Epoch: 16 [21760/35339 (61%)]\tLoss: 0.004017\n",
            "Train Epoch: 16 [22400/35339 (63%)]\tLoss: 0.000916\n",
            "Train Epoch: 16 [23040/35339 (65%)]\tLoss: 0.009662\n",
            "Train Epoch: 16 [23680/35339 (67%)]\tLoss: 0.001288\n",
            "Train Epoch: 16 [24320/35339 (69%)]\tLoss: 0.004880\n",
            "Train Epoch: 16 [24960/35339 (71%)]\tLoss: 0.011495\n",
            "Train Epoch: 16 [25600/35339 (72%)]\tLoss: 0.148449\n",
            "Train Epoch: 16 [26240/35339 (74%)]\tLoss: 0.006706\n",
            "Train Epoch: 16 [26880/35339 (76%)]\tLoss: 0.005889\n",
            "Train Epoch: 16 [27520/35339 (78%)]\tLoss: 0.003551\n",
            "Train Epoch: 16 [28160/35339 (80%)]\tLoss: 0.008669\n",
            "Train Epoch: 16 [28800/35339 (81%)]\tLoss: 0.023957\n",
            "Train Epoch: 16 [29440/35339 (83%)]\tLoss: 0.062305\n",
            "Train Epoch: 16 [30080/35339 (85%)]\tLoss: 0.002885\n",
            "Train Epoch: 16 [30720/35339 (87%)]\tLoss: 0.012153\n",
            "Train Epoch: 16 [31360/35339 (89%)]\tLoss: 0.001343\n",
            "Train Epoch: 16 [32000/35339 (90%)]\tLoss: 0.002279\n",
            "Train Epoch: 16 [32640/35339 (92%)]\tLoss: 0.000958\n",
            "Train Epoch: 16 [33280/35339 (94%)]\tLoss: 0.039001\n",
            "Train Epoch: 16 [33920/35339 (96%)]\tLoss: 0.007096\n",
            "Train Epoch: 16 [34560/35339 (98%)]\tLoss: 0.029858\n",
            "Train Epoch: 16 [35200/35339 (99%)]\tLoss: 0.008636\n",
            "\n",
            "Validation set: Average loss: 0.1227, Accuracy: 3742/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_16.pth.\n",
            "Train Epoch: 17 [0/35339 (0%)]\tLoss: 0.030734\n",
            "Train Epoch: 17 [640/35339 (2%)]\tLoss: 0.117071\n",
            "Train Epoch: 17 [1280/35339 (4%)]\tLoss: 0.008599\n",
            "Train Epoch: 17 [1920/35339 (5%)]\tLoss: 0.001274\n",
            "Train Epoch: 17 [2560/35339 (7%)]\tLoss: 0.003886\n",
            "Train Epoch: 17 [3200/35339 (9%)]\tLoss: 0.008381\n",
            "Train Epoch: 17 [3840/35339 (11%)]\tLoss: 0.002206\n",
            "Train Epoch: 17 [4480/35339 (13%)]\tLoss: 0.033868\n",
            "Train Epoch: 17 [5120/35339 (14%)]\tLoss: 0.113204\n",
            "Train Epoch: 17 [5760/35339 (16%)]\tLoss: 0.060959\n",
            "Train Epoch: 17 [6400/35339 (18%)]\tLoss: 0.010940\n",
            "Train Epoch: 17 [7040/35339 (20%)]\tLoss: 0.016232\n",
            "Train Epoch: 17 [7680/35339 (22%)]\tLoss: 0.084403\n",
            "Train Epoch: 17 [8320/35339 (24%)]\tLoss: 0.007549\n",
            "Train Epoch: 17 [8960/35339 (25%)]\tLoss: 0.067471\n",
            "Train Epoch: 17 [9600/35339 (27%)]\tLoss: 0.005232\n",
            "Train Epoch: 17 [10240/35339 (29%)]\tLoss: 0.026512\n",
            "Train Epoch: 17 [10880/35339 (31%)]\tLoss: 0.010022\n",
            "Train Epoch: 17 [11520/35339 (33%)]\tLoss: 0.071621\n",
            "Train Epoch: 17 [12160/35339 (34%)]\tLoss: 0.007354\n",
            "Train Epoch: 17 [12800/35339 (36%)]\tLoss: 0.037707\n",
            "Train Epoch: 17 [13440/35339 (38%)]\tLoss: 0.036686\n",
            "Train Epoch: 17 [14080/35339 (40%)]\tLoss: 0.007265\n",
            "Train Epoch: 17 [14720/35339 (42%)]\tLoss: 0.077748\n",
            "Train Epoch: 17 [15360/35339 (43%)]\tLoss: 0.001360\n",
            "Train Epoch: 17 [16000/35339 (45%)]\tLoss: 0.028698\n",
            "Train Epoch: 17 [16640/35339 (47%)]\tLoss: 0.165026\n",
            "Train Epoch: 17 [17280/35339 (49%)]\tLoss: 0.046030\n",
            "Train Epoch: 17 [17920/35339 (51%)]\tLoss: 0.035080\n",
            "Train Epoch: 17 [18560/35339 (52%)]\tLoss: 0.013421\n",
            "Train Epoch: 17 [19200/35339 (54%)]\tLoss: 0.081255\n",
            "Train Epoch: 17 [19840/35339 (56%)]\tLoss: 0.000942\n",
            "Train Epoch: 17 [20480/35339 (58%)]\tLoss: 0.008896\n",
            "Train Epoch: 17 [21120/35339 (60%)]\tLoss: 0.048801\n",
            "Train Epoch: 17 [21760/35339 (61%)]\tLoss: 0.001425\n",
            "Train Epoch: 17 [22400/35339 (63%)]\tLoss: 0.003951\n",
            "Train Epoch: 17 [23040/35339 (65%)]\tLoss: 0.055911\n",
            "Train Epoch: 17 [23680/35339 (67%)]\tLoss: 0.001162\n",
            "Train Epoch: 17 [24320/35339 (69%)]\tLoss: 0.092884\n",
            "Train Epoch: 17 [24960/35339 (71%)]\tLoss: 0.038570\n",
            "Train Epoch: 17 [25600/35339 (72%)]\tLoss: 0.048770\n",
            "Train Epoch: 17 [26240/35339 (74%)]\tLoss: 0.014264\n",
            "Train Epoch: 17 [26880/35339 (76%)]\tLoss: 0.002311\n",
            "Train Epoch: 17 [27520/35339 (78%)]\tLoss: 0.033584\n",
            "Train Epoch: 17 [28160/35339 (80%)]\tLoss: 0.005147\n",
            "Train Epoch: 17 [28800/35339 (81%)]\tLoss: 0.028167\n",
            "Train Epoch: 17 [29440/35339 (83%)]\tLoss: 0.019567\n",
            "Train Epoch: 17 [30080/35339 (85%)]\tLoss: 0.050149\n",
            "Train Epoch: 17 [30720/35339 (87%)]\tLoss: 0.001685\n",
            "Train Epoch: 17 [31360/35339 (89%)]\tLoss: 0.056797\n",
            "Train Epoch: 17 [32000/35339 (90%)]\tLoss: 0.045554\n",
            "Train Epoch: 17 [32640/35339 (92%)]\tLoss: 0.039011\n",
            "Train Epoch: 17 [33280/35339 (94%)]\tLoss: 0.003034\n",
            "Train Epoch: 17 [33920/35339 (96%)]\tLoss: 0.045802\n",
            "Train Epoch: 17 [34560/35339 (98%)]\tLoss: 0.010725\n",
            "Train Epoch: 17 [35200/35339 (99%)]\tLoss: 0.008542\n",
            "\n",
            "Validation set: Average loss: 0.0897, Accuracy: 3782/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_17.pth.\n",
            "Train Epoch: 18 [0/35339 (0%)]\tLoss: 0.002168\n",
            "Train Epoch: 18 [640/35339 (2%)]\tLoss: 0.006786\n",
            "Train Epoch: 18 [1280/35339 (4%)]\tLoss: 0.017752\n",
            "Train Epoch: 18 [1920/35339 (5%)]\tLoss: 0.003305\n",
            "Train Epoch: 18 [2560/35339 (7%)]\tLoss: 0.010813\n",
            "Train Epoch: 18 [3200/35339 (9%)]\tLoss: 0.085207\n",
            "Train Epoch: 18 [3840/35339 (11%)]\tLoss: 0.016949\n",
            "Train Epoch: 18 [4480/35339 (13%)]\tLoss: 0.051579\n",
            "Train Epoch: 18 [5120/35339 (14%)]\tLoss: 0.002135\n",
            "Train Epoch: 18 [5760/35339 (16%)]\tLoss: 0.019011\n",
            "Train Epoch: 18 [6400/35339 (18%)]\tLoss: 0.009909\n",
            "Train Epoch: 18 [7040/35339 (20%)]\tLoss: 0.032706\n",
            "Train Epoch: 18 [7680/35339 (22%)]\tLoss: 0.011162\n",
            "Train Epoch: 18 [8320/35339 (24%)]\tLoss: 0.002808\n",
            "Train Epoch: 18 [8960/35339 (25%)]\tLoss: 0.064200\n",
            "Train Epoch: 18 [9600/35339 (27%)]\tLoss: 0.015322\n",
            "Train Epoch: 18 [10240/35339 (29%)]\tLoss: 0.008402\n",
            "Train Epoch: 18 [10880/35339 (31%)]\tLoss: 0.043863\n",
            "Train Epoch: 18 [11520/35339 (33%)]\tLoss: 0.002951\n",
            "Train Epoch: 18 [12160/35339 (34%)]\tLoss: 0.007470\n",
            "Train Epoch: 18 [12800/35339 (36%)]\tLoss: 0.049210\n",
            "Train Epoch: 18 [13440/35339 (38%)]\tLoss: 0.040657\n",
            "Train Epoch: 18 [14080/35339 (40%)]\tLoss: 0.008733\n",
            "Train Epoch: 18 [14720/35339 (42%)]\tLoss: 0.018826\n",
            "Train Epoch: 18 [15360/35339 (43%)]\tLoss: 0.039550\n",
            "Train Epoch: 18 [16000/35339 (45%)]\tLoss: 0.046495\n",
            "Train Epoch: 18 [16640/35339 (47%)]\tLoss: 0.010567\n",
            "Train Epoch: 18 [17280/35339 (49%)]\tLoss: 0.010929\n",
            "Train Epoch: 18 [17920/35339 (51%)]\tLoss: 0.025335\n",
            "Train Epoch: 18 [18560/35339 (52%)]\tLoss: 0.212415\n",
            "Train Epoch: 18 [19200/35339 (54%)]\tLoss: 0.002135\n",
            "Train Epoch: 18 [19840/35339 (56%)]\tLoss: 0.034533\n",
            "Train Epoch: 18 [20480/35339 (58%)]\tLoss: 0.007233\n",
            "Train Epoch: 18 [21120/35339 (60%)]\tLoss: 0.005861\n",
            "Train Epoch: 18 [21760/35339 (61%)]\tLoss: 0.050712\n",
            "Train Epoch: 18 [22400/35339 (63%)]\tLoss: 0.003588\n",
            "Train Epoch: 18 [23040/35339 (65%)]\tLoss: 0.137137\n",
            "Train Epoch: 18 [23680/35339 (67%)]\tLoss: 0.057043\n",
            "Train Epoch: 18 [24320/35339 (69%)]\tLoss: 0.061222\n",
            "Train Epoch: 18 [24960/35339 (71%)]\tLoss: 0.003649\n",
            "Train Epoch: 18 [25600/35339 (72%)]\tLoss: 0.002902\n",
            "Train Epoch: 18 [26240/35339 (74%)]\tLoss: 0.002471\n",
            "Train Epoch: 18 [26880/35339 (76%)]\tLoss: 0.007462\n",
            "Train Epoch: 18 [27520/35339 (78%)]\tLoss: 0.020269\n",
            "Train Epoch: 18 [28160/35339 (80%)]\tLoss: 0.001696\n",
            "Train Epoch: 18 [28800/35339 (81%)]\tLoss: 0.089918\n",
            "Train Epoch: 18 [29440/35339 (83%)]\tLoss: 0.010409\n",
            "Train Epoch: 18 [30080/35339 (85%)]\tLoss: 0.012104\n",
            "Train Epoch: 18 [30720/35339 (87%)]\tLoss: 0.004822\n",
            "Train Epoch: 18 [31360/35339 (89%)]\tLoss: 0.005993\n",
            "Train Epoch: 18 [32000/35339 (90%)]\tLoss: 0.058206\n",
            "Train Epoch: 18 [32640/35339 (92%)]\tLoss: 0.015445\n",
            "Train Epoch: 18 [33280/35339 (94%)]\tLoss: 0.019006\n",
            "Train Epoch: 18 [33920/35339 (96%)]\tLoss: 0.001361\n",
            "Train Epoch: 18 [34560/35339 (98%)]\tLoss: 0.025148\n",
            "Train Epoch: 18 [35200/35339 (99%)]\tLoss: 0.011941\n",
            "\n",
            "Validation set: Average loss: 0.1051, Accuracy: 3766/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_18.pth.\n",
            "Train Epoch: 19 [0/35339 (0%)]\tLoss: 0.001684\n",
            "Train Epoch: 19 [640/35339 (2%)]\tLoss: 0.154215\n",
            "Train Epoch: 19 [1280/35339 (4%)]\tLoss: 0.017428\n",
            "Train Epoch: 19 [1920/35339 (5%)]\tLoss: 0.039989\n",
            "Train Epoch: 19 [2560/35339 (7%)]\tLoss: 0.013875\n",
            "Train Epoch: 19 [3200/35339 (9%)]\tLoss: 0.089700\n",
            "Train Epoch: 19 [3840/35339 (11%)]\tLoss: 0.035049\n",
            "Train Epoch: 19 [4480/35339 (13%)]\tLoss: 0.019071\n",
            "Train Epoch: 19 [5120/35339 (14%)]\tLoss: 0.004205\n",
            "Train Epoch: 19 [5760/35339 (16%)]\tLoss: 0.015502\n",
            "Train Epoch: 19 [6400/35339 (18%)]\tLoss: 0.004790\n",
            "Train Epoch: 19 [7040/35339 (20%)]\tLoss: 0.001290\n",
            "Train Epoch: 19 [7680/35339 (22%)]\tLoss: 0.008319\n",
            "Train Epoch: 19 [8320/35339 (24%)]\tLoss: 0.015435\n",
            "Train Epoch: 19 [8960/35339 (25%)]\tLoss: 0.000931\n",
            "Train Epoch: 19 [9600/35339 (27%)]\tLoss: 0.003903\n",
            "Train Epoch: 19 [10240/35339 (29%)]\tLoss: 0.031183\n",
            "Train Epoch: 19 [10880/35339 (31%)]\tLoss: 0.021219\n",
            "Train Epoch: 19 [11520/35339 (33%)]\tLoss: 0.027171\n",
            "Train Epoch: 19 [12160/35339 (34%)]\tLoss: 0.010054\n",
            "Train Epoch: 19 [12800/35339 (36%)]\tLoss: 0.011562\n",
            "Train Epoch: 19 [13440/35339 (38%)]\tLoss: 0.009105\n",
            "Train Epoch: 19 [14080/35339 (40%)]\tLoss: 0.004008\n",
            "Train Epoch: 19 [14720/35339 (42%)]\tLoss: 0.011352\n",
            "Train Epoch: 19 [15360/35339 (43%)]\tLoss: 0.023606\n",
            "Train Epoch: 19 [16000/35339 (45%)]\tLoss: 0.003931\n",
            "Train Epoch: 19 [16640/35339 (47%)]\tLoss: 0.044627\n",
            "Train Epoch: 19 [17280/35339 (49%)]\tLoss: 0.003093\n",
            "Train Epoch: 19 [17920/35339 (51%)]\tLoss: 0.030013\n",
            "Train Epoch: 19 [18560/35339 (52%)]\tLoss: 0.040220\n",
            "Train Epoch: 19 [19200/35339 (54%)]\tLoss: 0.015685\n",
            "Train Epoch: 19 [19840/35339 (56%)]\tLoss: 0.000123\n",
            "Train Epoch: 19 [20480/35339 (58%)]\tLoss: 0.001704\n",
            "Train Epoch: 19 [21120/35339 (60%)]\tLoss: 0.016456\n",
            "Train Epoch: 19 [21760/35339 (61%)]\tLoss: 0.034564\n",
            "Train Epoch: 19 [22400/35339 (63%)]\tLoss: 0.009240\n",
            "Train Epoch: 19 [23040/35339 (65%)]\tLoss: 0.035820\n",
            "Train Epoch: 19 [23680/35339 (67%)]\tLoss: 0.011259\n",
            "Train Epoch: 19 [24320/35339 (69%)]\tLoss: 0.081777\n",
            "Train Epoch: 19 [24960/35339 (71%)]\tLoss: 0.001111\n",
            "Train Epoch: 19 [25600/35339 (72%)]\tLoss: 0.004178\n",
            "Train Epoch: 19 [26240/35339 (74%)]\tLoss: 0.061741\n",
            "Train Epoch: 19 [26880/35339 (76%)]\tLoss: 0.025976\n",
            "Train Epoch: 19 [27520/35339 (78%)]\tLoss: 0.003273\n",
            "Train Epoch: 19 [28160/35339 (80%)]\tLoss: 0.018008\n",
            "Train Epoch: 19 [28800/35339 (81%)]\tLoss: 0.005563\n",
            "Train Epoch: 19 [29440/35339 (83%)]\tLoss: 0.042611\n",
            "Train Epoch: 19 [30080/35339 (85%)]\tLoss: 0.003782\n",
            "Train Epoch: 19 [30720/35339 (87%)]\tLoss: 0.041446\n",
            "Train Epoch: 19 [31360/35339 (89%)]\tLoss: 0.001792\n",
            "Train Epoch: 19 [32000/35339 (90%)]\tLoss: 0.034325\n",
            "Train Epoch: 19 [32640/35339 (92%)]\tLoss: 0.000277\n",
            "Train Epoch: 19 [33280/35339 (94%)]\tLoss: 0.101275\n",
            "Train Epoch: 19 [33920/35339 (96%)]\tLoss: 0.012815\n",
            "Train Epoch: 19 [34560/35339 (98%)]\tLoss: 0.023705\n",
            "Train Epoch: 19 [35200/35339 (99%)]\tLoss: 0.001414\n",
            "\n",
            "Validation set: Average loss: 0.1212, Accuracy: 3741/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_19.pth.\n",
            "Train Epoch: 20 [0/35339 (0%)]\tLoss: 0.004841\n",
            "Train Epoch: 20 [640/35339 (2%)]\tLoss: 0.049512\n",
            "Train Epoch: 20 [1280/35339 (4%)]\tLoss: 0.004428\n",
            "Train Epoch: 20 [1920/35339 (5%)]\tLoss: 0.075873\n",
            "Train Epoch: 20 [2560/35339 (7%)]\tLoss: 0.072744\n",
            "Train Epoch: 20 [3200/35339 (9%)]\tLoss: 0.001003\n",
            "Train Epoch: 20 [3840/35339 (11%)]\tLoss: 0.058615\n",
            "Train Epoch: 20 [4480/35339 (13%)]\tLoss: 0.031279\n",
            "Train Epoch: 20 [5120/35339 (14%)]\tLoss: 0.006029\n",
            "Train Epoch: 20 [5760/35339 (16%)]\tLoss: 0.005126\n",
            "Train Epoch: 20 [6400/35339 (18%)]\tLoss: 0.003409\n",
            "Train Epoch: 20 [7040/35339 (20%)]\tLoss: 0.005609\n",
            "Train Epoch: 20 [7680/35339 (22%)]\tLoss: 0.005429\n",
            "Train Epoch: 20 [8320/35339 (24%)]\tLoss: 0.036187\n",
            "Train Epoch: 20 [8960/35339 (25%)]\tLoss: 0.019022\n",
            "Train Epoch: 20 [9600/35339 (27%)]\tLoss: 0.020771\n",
            "Train Epoch: 20 [10240/35339 (29%)]\tLoss: 0.011948\n",
            "Train Epoch: 20 [10880/35339 (31%)]\tLoss: 0.053774\n",
            "Train Epoch: 20 [11520/35339 (33%)]\tLoss: 0.028957\n",
            "Train Epoch: 20 [12160/35339 (34%)]\tLoss: 0.040375\n",
            "Train Epoch: 20 [12800/35339 (36%)]\tLoss: 0.033416\n",
            "Train Epoch: 20 [13440/35339 (38%)]\tLoss: 0.040796\n",
            "Train Epoch: 20 [14080/35339 (40%)]\tLoss: 0.018535\n",
            "Train Epoch: 20 [14720/35339 (42%)]\tLoss: 0.102745\n",
            "Train Epoch: 20 [15360/35339 (43%)]\tLoss: 0.008413\n",
            "Train Epoch: 20 [16000/35339 (45%)]\tLoss: 0.010380\n",
            "Train Epoch: 20 [16640/35339 (47%)]\tLoss: 0.003079\n",
            "Train Epoch: 20 [17280/35339 (49%)]\tLoss: 0.010773\n",
            "Train Epoch: 20 [17920/35339 (51%)]\tLoss: 0.049422\n",
            "Train Epoch: 20 [18560/35339 (52%)]\tLoss: 0.004019\n",
            "Train Epoch: 20 [19200/35339 (54%)]\tLoss: 0.034157\n",
            "Train Epoch: 20 [19840/35339 (56%)]\tLoss: 0.021106\n",
            "Train Epoch: 20 [20480/35339 (58%)]\tLoss: 0.004774\n",
            "Train Epoch: 20 [21120/35339 (60%)]\tLoss: 0.022983\n",
            "Train Epoch: 20 [21760/35339 (61%)]\tLoss: 0.003987\n",
            "Train Epoch: 20 [22400/35339 (63%)]\tLoss: 0.020198\n",
            "Train Epoch: 20 [23040/35339 (65%)]\tLoss: 0.118744\n",
            "Train Epoch: 20 [23680/35339 (67%)]\tLoss: 0.000676\n",
            "Train Epoch: 20 [24320/35339 (69%)]\tLoss: 0.041748\n",
            "Train Epoch: 20 [24960/35339 (71%)]\tLoss: 0.005978\n",
            "Train Epoch: 20 [25600/35339 (72%)]\tLoss: 0.163751\n",
            "Train Epoch: 20 [26240/35339 (74%)]\tLoss: 0.001764\n",
            "Train Epoch: 20 [26880/35339 (76%)]\tLoss: 0.206953\n",
            "Train Epoch: 20 [27520/35339 (78%)]\tLoss: 0.001026\n",
            "Train Epoch: 20 [28160/35339 (80%)]\tLoss: 0.007026\n",
            "Train Epoch: 20 [28800/35339 (81%)]\tLoss: 0.073188\n",
            "Train Epoch: 20 [29440/35339 (83%)]\tLoss: 0.000277\n",
            "Train Epoch: 20 [30080/35339 (85%)]\tLoss: 0.008354\n",
            "Train Epoch: 20 [30720/35339 (87%)]\tLoss: 0.121752\n",
            "Train Epoch: 20 [31360/35339 (89%)]\tLoss: 0.003770\n",
            "Train Epoch: 20 [32000/35339 (90%)]\tLoss: 0.040657\n",
            "Train Epoch: 20 [32640/35339 (92%)]\tLoss: 0.103015\n",
            "Train Epoch: 20 [33280/35339 (94%)]\tLoss: 0.102501\n",
            "Train Epoch: 20 [33920/35339 (96%)]\tLoss: 0.023497\n",
            "Train Epoch: 20 [34560/35339 (98%)]\tLoss: 0.010891\n",
            "Train Epoch: 20 [35200/35339 (99%)]\tLoss: 0.001264\n",
            "\n",
            "Validation set: Average loss: 0.1156, Accuracy: 3759/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_20.pth.\n",
            "Train Epoch: 21 [0/35339 (0%)]\tLoss: 0.003329\n",
            "Train Epoch: 21 [640/35339 (2%)]\tLoss: 0.024230\n",
            "Train Epoch: 21 [1280/35339 (4%)]\tLoss: 0.061303\n",
            "Train Epoch: 21 [1920/35339 (5%)]\tLoss: 0.067172\n",
            "Train Epoch: 21 [2560/35339 (7%)]\tLoss: 0.037776\n",
            "Train Epoch: 21 [3200/35339 (9%)]\tLoss: 0.009658\n",
            "Train Epoch: 21 [3840/35339 (11%)]\tLoss: 0.010559\n",
            "Train Epoch: 21 [4480/35339 (13%)]\tLoss: 0.001637\n",
            "Train Epoch: 21 [5120/35339 (14%)]\tLoss: 0.003432\n",
            "Train Epoch: 21 [5760/35339 (16%)]\tLoss: 0.086534\n",
            "Train Epoch: 21 [6400/35339 (18%)]\tLoss: 0.069619\n",
            "Train Epoch: 21 [7040/35339 (20%)]\tLoss: 0.001880\n",
            "Train Epoch: 21 [7680/35339 (22%)]\tLoss: 0.022658\n",
            "Train Epoch: 21 [8320/35339 (24%)]\tLoss: 0.000779\n",
            "Train Epoch: 21 [8960/35339 (25%)]\tLoss: 0.000234\n",
            "Train Epoch: 21 [9600/35339 (27%)]\tLoss: 0.002762\n",
            "Train Epoch: 21 [10240/35339 (29%)]\tLoss: 0.001180\n",
            "Train Epoch: 21 [10880/35339 (31%)]\tLoss: 0.045167\n",
            "Train Epoch: 21 [11520/35339 (33%)]\tLoss: 0.039945\n",
            "Train Epoch: 21 [12160/35339 (34%)]\tLoss: 0.000752\n",
            "Train Epoch: 21 [12800/35339 (36%)]\tLoss: 0.021121\n",
            "Train Epoch: 21 [13440/35339 (38%)]\tLoss: 0.100253\n",
            "Train Epoch: 21 [14080/35339 (40%)]\tLoss: 0.012480\n",
            "Train Epoch: 21 [14720/35339 (42%)]\tLoss: 0.058036\n",
            "Train Epoch: 21 [15360/35339 (43%)]\tLoss: 0.003947\n",
            "Train Epoch: 21 [16000/35339 (45%)]\tLoss: 0.005035\n",
            "Train Epoch: 21 [16640/35339 (47%)]\tLoss: 0.000794\n",
            "Train Epoch: 21 [17280/35339 (49%)]\tLoss: 0.222979\n",
            "Train Epoch: 21 [17920/35339 (51%)]\tLoss: 0.005776\n",
            "Train Epoch: 21 [18560/35339 (52%)]\tLoss: 0.034837\n",
            "Train Epoch: 21 [19200/35339 (54%)]\tLoss: 0.012721\n",
            "Train Epoch: 21 [19840/35339 (56%)]\tLoss: 0.001887\n",
            "Train Epoch: 21 [20480/35339 (58%)]\tLoss: 0.000689\n",
            "Train Epoch: 21 [21120/35339 (60%)]\tLoss: 0.020747\n",
            "Train Epoch: 21 [21760/35339 (61%)]\tLoss: 0.006582\n",
            "Train Epoch: 21 [22400/35339 (63%)]\tLoss: 0.002132\n",
            "Train Epoch: 21 [23040/35339 (65%)]\tLoss: 0.024763\n",
            "Train Epoch: 21 [23680/35339 (67%)]\tLoss: 0.012954\n",
            "Train Epoch: 21 [24320/35339 (69%)]\tLoss: 0.011155\n",
            "Train Epoch: 21 [24960/35339 (71%)]\tLoss: 0.011073\n",
            "Train Epoch: 21 [25600/35339 (72%)]\tLoss: 0.002206\n",
            "Train Epoch: 21 [26240/35339 (74%)]\tLoss: 0.049669\n",
            "Train Epoch: 21 [26880/35339 (76%)]\tLoss: 0.008241\n",
            "Train Epoch: 21 [27520/35339 (78%)]\tLoss: 0.001157\n",
            "Train Epoch: 21 [28160/35339 (80%)]\tLoss: 0.021241\n",
            "Train Epoch: 21 [28800/35339 (81%)]\tLoss: 0.027276\n",
            "Train Epoch: 21 [29440/35339 (83%)]\tLoss: 0.018339\n",
            "Train Epoch: 21 [30080/35339 (85%)]\tLoss: 0.004346\n",
            "Train Epoch: 21 [30720/35339 (87%)]\tLoss: 0.021647\n",
            "Train Epoch: 21 [31360/35339 (89%)]\tLoss: 0.011032\n",
            "Train Epoch: 21 [32000/35339 (90%)]\tLoss: 0.062027\n",
            "Train Epoch: 21 [32640/35339 (92%)]\tLoss: 0.044204\n",
            "Train Epoch: 21 [33280/35339 (94%)]\tLoss: 0.031839\n",
            "Train Epoch: 21 [33920/35339 (96%)]\tLoss: 0.012092\n",
            "Train Epoch: 21 [34560/35339 (98%)]\tLoss: 0.090930\n",
            "Train Epoch: 21 [35200/35339 (99%)]\tLoss: 0.118089\n",
            "\n",
            "Validation set: Average loss: 0.1388, Accuracy: 3751/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_21.pth.\n",
            "Train Epoch: 22 [0/35339 (0%)]\tLoss: 0.000395\n",
            "Train Epoch: 22 [640/35339 (2%)]\tLoss: 0.006285\n",
            "Train Epoch: 22 [1280/35339 (4%)]\tLoss: 0.030398\n",
            "Train Epoch: 22 [1920/35339 (5%)]\tLoss: 0.003261\n",
            "Train Epoch: 22 [2560/35339 (7%)]\tLoss: 0.005645\n",
            "Train Epoch: 22 [3200/35339 (9%)]\tLoss: 0.006259\n",
            "Train Epoch: 22 [3840/35339 (11%)]\tLoss: 0.024928\n",
            "Train Epoch: 22 [4480/35339 (13%)]\tLoss: 0.004572\n",
            "Train Epoch: 22 [5120/35339 (14%)]\tLoss: 0.012170\n",
            "Train Epoch: 22 [5760/35339 (16%)]\tLoss: 0.005744\n",
            "Train Epoch: 22 [6400/35339 (18%)]\tLoss: 0.085126\n",
            "Train Epoch: 22 [7040/35339 (20%)]\tLoss: 0.000652\n",
            "Train Epoch: 22 [7680/35339 (22%)]\tLoss: 0.005371\n",
            "Train Epoch: 22 [8320/35339 (24%)]\tLoss: 0.029759\n",
            "Train Epoch: 22 [8960/35339 (25%)]\tLoss: 0.015883\n",
            "Train Epoch: 22 [9600/35339 (27%)]\tLoss: 0.007744\n",
            "Train Epoch: 22 [10240/35339 (29%)]\tLoss: 0.084282\n",
            "Train Epoch: 22 [10880/35339 (31%)]\tLoss: 0.002195\n",
            "Train Epoch: 22 [11520/35339 (33%)]\tLoss: 0.012885\n",
            "Train Epoch: 22 [12160/35339 (34%)]\tLoss: 0.002912\n",
            "Train Epoch: 22 [12800/35339 (36%)]\tLoss: 0.041767\n",
            "Train Epoch: 22 [13440/35339 (38%)]\tLoss: 0.000633\n",
            "Train Epoch: 22 [14080/35339 (40%)]\tLoss: 0.029125\n",
            "Train Epoch: 22 [14720/35339 (42%)]\tLoss: 0.066998\n",
            "Train Epoch: 22 [15360/35339 (43%)]\tLoss: 0.042970\n",
            "Train Epoch: 22 [16000/35339 (45%)]\tLoss: 0.055282\n",
            "Train Epoch: 22 [16640/35339 (47%)]\tLoss: 0.061801\n",
            "Train Epoch: 22 [17280/35339 (49%)]\tLoss: 0.078741\n",
            "Train Epoch: 22 [17920/35339 (51%)]\tLoss: 0.011121\n",
            "Train Epoch: 22 [18560/35339 (52%)]\tLoss: 0.009118\n",
            "Train Epoch: 22 [19200/35339 (54%)]\tLoss: 0.013544\n",
            "Train Epoch: 22 [19840/35339 (56%)]\tLoss: 0.015918\n",
            "Train Epoch: 22 [20480/35339 (58%)]\tLoss: 0.005081\n",
            "Train Epoch: 22 [21120/35339 (60%)]\tLoss: 0.003645\n",
            "Train Epoch: 22 [21760/35339 (61%)]\tLoss: 0.004146\n",
            "Train Epoch: 22 [22400/35339 (63%)]\tLoss: 0.380056\n",
            "Train Epoch: 22 [23040/35339 (65%)]\tLoss: 0.024175\n",
            "Train Epoch: 22 [23680/35339 (67%)]\tLoss: 0.030597\n",
            "Train Epoch: 22 [24320/35339 (69%)]\tLoss: 0.071341\n",
            "Train Epoch: 22 [24960/35339 (71%)]\tLoss: 0.028354\n",
            "Train Epoch: 22 [25600/35339 (72%)]\tLoss: 0.011596\n",
            "Train Epoch: 22 [26240/35339 (74%)]\tLoss: 0.003372\n",
            "Train Epoch: 22 [26880/35339 (76%)]\tLoss: 0.003447\n",
            "Train Epoch: 22 [27520/35339 (78%)]\tLoss: 0.016492\n",
            "Train Epoch: 22 [28160/35339 (80%)]\tLoss: 0.003885\n",
            "Train Epoch: 22 [28800/35339 (81%)]\tLoss: 0.042829\n",
            "Train Epoch: 22 [29440/35339 (83%)]\tLoss: 0.046508\n",
            "Train Epoch: 22 [30080/35339 (85%)]\tLoss: 0.004308\n",
            "Train Epoch: 22 [30720/35339 (87%)]\tLoss: 0.009439\n",
            "Train Epoch: 22 [31360/35339 (89%)]\tLoss: 0.010515\n",
            "Train Epoch: 22 [32000/35339 (90%)]\tLoss: 0.095776\n",
            "Train Epoch: 22 [32640/35339 (92%)]\tLoss: 0.012283\n",
            "Train Epoch: 22 [33280/35339 (94%)]\tLoss: 0.046823\n",
            "Train Epoch: 22 [33920/35339 (96%)]\tLoss: 0.085606\n",
            "Train Epoch: 22 [34560/35339 (98%)]\tLoss: 0.007471\n",
            "Train Epoch: 22 [35200/35339 (99%)]\tLoss: 0.006525\n",
            "\n",
            "Validation set: Average loss: 0.1111, Accuracy: 3765/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_22.pth.\n",
            "Train Epoch: 23 [0/35339 (0%)]\tLoss: 0.063294\n",
            "Train Epoch: 23 [640/35339 (2%)]\tLoss: 0.021437\n",
            "Train Epoch: 23 [1280/35339 (4%)]\tLoss: 0.057452\n",
            "Train Epoch: 23 [1920/35339 (5%)]\tLoss: 0.001707\n",
            "Train Epoch: 23 [2560/35339 (7%)]\tLoss: 0.209045\n",
            "Train Epoch: 23 [3200/35339 (9%)]\tLoss: 0.004110\n",
            "Train Epoch: 23 [3840/35339 (11%)]\tLoss: 0.029464\n",
            "Train Epoch: 23 [4480/35339 (13%)]\tLoss: 0.050188\n",
            "Train Epoch: 23 [5120/35339 (14%)]\tLoss: 0.025502\n",
            "Train Epoch: 23 [5760/35339 (16%)]\tLoss: 0.078819\n",
            "Train Epoch: 23 [6400/35339 (18%)]\tLoss: 0.002607\n",
            "Train Epoch: 23 [7040/35339 (20%)]\tLoss: 0.003555\n",
            "Train Epoch: 23 [7680/35339 (22%)]\tLoss: 0.003349\n",
            "Train Epoch: 23 [8320/35339 (24%)]\tLoss: 0.002500\n",
            "Train Epoch: 23 [8960/35339 (25%)]\tLoss: 0.018538\n",
            "Train Epoch: 23 [9600/35339 (27%)]\tLoss: 0.026498\n",
            "Train Epoch: 23 [10240/35339 (29%)]\tLoss: 0.002133\n",
            "Train Epoch: 23 [10880/35339 (31%)]\tLoss: 0.134322\n",
            "Train Epoch: 23 [11520/35339 (33%)]\tLoss: 0.009563\n",
            "Train Epoch: 23 [12160/35339 (34%)]\tLoss: 0.003178\n",
            "Train Epoch: 23 [12800/35339 (36%)]\tLoss: 0.036437\n",
            "Train Epoch: 23 [13440/35339 (38%)]\tLoss: 0.024506\n",
            "Train Epoch: 23 [14080/35339 (40%)]\tLoss: 0.034173\n",
            "Train Epoch: 23 [14720/35339 (42%)]\tLoss: 0.000239\n",
            "Train Epoch: 23 [15360/35339 (43%)]\tLoss: 0.044568\n",
            "Train Epoch: 23 [16000/35339 (45%)]\tLoss: 0.032961\n",
            "Train Epoch: 23 [16640/35339 (47%)]\tLoss: 0.000046\n",
            "Train Epoch: 23 [17280/35339 (49%)]\tLoss: 0.004885\n",
            "Train Epoch: 23 [17920/35339 (51%)]\tLoss: 0.005638\n",
            "Train Epoch: 23 [18560/35339 (52%)]\tLoss: 0.000437\n",
            "Train Epoch: 23 [19200/35339 (54%)]\tLoss: 0.000598\n",
            "Train Epoch: 23 [19840/35339 (56%)]\tLoss: 0.001699\n",
            "Train Epoch: 23 [20480/35339 (58%)]\tLoss: 0.001083\n",
            "Train Epoch: 23 [21120/35339 (60%)]\tLoss: 0.017097\n",
            "Train Epoch: 23 [21760/35339 (61%)]\tLoss: 0.008284\n",
            "Train Epoch: 23 [22400/35339 (63%)]\tLoss: 0.015950\n",
            "Train Epoch: 23 [23040/35339 (65%)]\tLoss: 0.004911\n",
            "Train Epoch: 23 [23680/35339 (67%)]\tLoss: 0.011949\n",
            "Train Epoch: 23 [24320/35339 (69%)]\tLoss: 0.000130\n",
            "Train Epoch: 23 [24960/35339 (71%)]\tLoss: 0.008624\n",
            "Train Epoch: 23 [25600/35339 (72%)]\tLoss: 0.016710\n",
            "Train Epoch: 23 [26240/35339 (74%)]\tLoss: 0.001671\n",
            "Train Epoch: 23 [26880/35339 (76%)]\tLoss: 0.025785\n",
            "Train Epoch: 23 [27520/35339 (78%)]\tLoss: 0.074044\n",
            "Train Epoch: 23 [28160/35339 (80%)]\tLoss: 0.011245\n",
            "Train Epoch: 23 [28800/35339 (81%)]\tLoss: 0.009942\n",
            "Train Epoch: 23 [29440/35339 (83%)]\tLoss: 0.029454\n",
            "Train Epoch: 23 [30080/35339 (85%)]\tLoss: 0.012280\n",
            "Train Epoch: 23 [30720/35339 (87%)]\tLoss: 0.003740\n",
            "Train Epoch: 23 [31360/35339 (89%)]\tLoss: 0.018185\n",
            "Train Epoch: 23 [32000/35339 (90%)]\tLoss: 0.059941\n",
            "Train Epoch: 23 [32640/35339 (92%)]\tLoss: 0.000236\n",
            "Train Epoch: 23 [33280/35339 (94%)]\tLoss: 0.001188\n",
            "Train Epoch: 23 [33920/35339 (96%)]\tLoss: 0.004276\n",
            "Train Epoch: 23 [34560/35339 (98%)]\tLoss: 0.000512\n",
            "Train Epoch: 23 [35200/35339 (99%)]\tLoss: 0.028919\n",
            "\n",
            "Validation set: Average loss: 0.0843, Accuracy: 3787/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_23.pth.\n",
            "\n",
            "Most accurate epoch so far: 23\n",
            "Train Epoch: 24 [0/35339 (0%)]\tLoss: 0.010311\n",
            "Train Epoch: 24 [640/35339 (2%)]\tLoss: 0.004654\n",
            "Train Epoch: 24 [1280/35339 (4%)]\tLoss: 0.022509\n",
            "Train Epoch: 24 [1920/35339 (5%)]\tLoss: 0.005304\n",
            "Train Epoch: 24 [2560/35339 (7%)]\tLoss: 0.009366\n",
            "Train Epoch: 24 [3200/35339 (9%)]\tLoss: 0.001486\n",
            "Train Epoch: 24 [3840/35339 (11%)]\tLoss: 0.001587\n",
            "Train Epoch: 24 [4480/35339 (13%)]\tLoss: 0.002897\n",
            "Train Epoch: 24 [5120/35339 (14%)]\tLoss: 0.001966\n",
            "Train Epoch: 24 [5760/35339 (16%)]\tLoss: 0.000690\n",
            "Train Epoch: 24 [6400/35339 (18%)]\tLoss: 0.028025\n",
            "Train Epoch: 24 [7040/35339 (20%)]\tLoss: 0.054909\n",
            "Train Epoch: 24 [7680/35339 (22%)]\tLoss: 0.000066\n",
            "Train Epoch: 24 [8320/35339 (24%)]\tLoss: 0.003562\n",
            "Train Epoch: 24 [8960/35339 (25%)]\tLoss: 0.018573\n",
            "Train Epoch: 24 [9600/35339 (27%)]\tLoss: 0.072921\n",
            "Train Epoch: 24 [10240/35339 (29%)]\tLoss: 0.003713\n",
            "Train Epoch: 24 [10880/35339 (31%)]\tLoss: 0.056933\n",
            "Train Epoch: 24 [11520/35339 (33%)]\tLoss: 0.058888\n",
            "Train Epoch: 24 [12160/35339 (34%)]\tLoss: 0.031316\n",
            "Train Epoch: 24 [12800/35339 (36%)]\tLoss: 0.013637\n",
            "Train Epoch: 24 [13440/35339 (38%)]\tLoss: 0.033578\n",
            "Train Epoch: 24 [14080/35339 (40%)]\tLoss: 0.002350\n",
            "Train Epoch: 24 [14720/35339 (42%)]\tLoss: 0.073891\n",
            "Train Epoch: 24 [15360/35339 (43%)]\tLoss: 0.020787\n",
            "Train Epoch: 24 [16000/35339 (45%)]\tLoss: 0.026297\n",
            "Train Epoch: 24 [16640/35339 (47%)]\tLoss: 0.000074\n",
            "Train Epoch: 24 [17280/35339 (49%)]\tLoss: 0.018726\n",
            "Train Epoch: 24 [17920/35339 (51%)]\tLoss: 0.082445\n",
            "Train Epoch: 24 [18560/35339 (52%)]\tLoss: 0.005599\n",
            "Train Epoch: 24 [19200/35339 (54%)]\tLoss: 0.001316\n",
            "Train Epoch: 24 [19840/35339 (56%)]\tLoss: 0.003922\n",
            "Train Epoch: 24 [20480/35339 (58%)]\tLoss: 0.000767\n",
            "Train Epoch: 24 [21120/35339 (60%)]\tLoss: 0.033424\n",
            "Train Epoch: 24 [21760/35339 (61%)]\tLoss: 0.000424\n",
            "Train Epoch: 24 [22400/35339 (63%)]\tLoss: 0.000763\n",
            "Train Epoch: 24 [23040/35339 (65%)]\tLoss: 0.000518\n",
            "Train Epoch: 24 [23680/35339 (67%)]\tLoss: 0.002517\n",
            "Train Epoch: 24 [24320/35339 (69%)]\tLoss: 0.006877\n",
            "Train Epoch: 24 [24960/35339 (71%)]\tLoss: 0.007485\n",
            "Train Epoch: 24 [25600/35339 (72%)]\tLoss: 0.001434\n",
            "Train Epoch: 24 [26240/35339 (74%)]\tLoss: 0.000756\n",
            "Train Epoch: 24 [26880/35339 (76%)]\tLoss: 0.035798\n",
            "Train Epoch: 24 [27520/35339 (78%)]\tLoss: 0.017329\n",
            "Train Epoch: 24 [28160/35339 (80%)]\tLoss: 0.000076\n",
            "Train Epoch: 24 [28800/35339 (81%)]\tLoss: 0.008975\n",
            "Train Epoch: 24 [29440/35339 (83%)]\tLoss: 0.005026\n",
            "Train Epoch: 24 [30080/35339 (85%)]\tLoss: 0.014129\n",
            "Train Epoch: 24 [30720/35339 (87%)]\tLoss: 0.000539\n",
            "Train Epoch: 24 [31360/35339 (89%)]\tLoss: 0.014078\n",
            "Train Epoch: 24 [32000/35339 (90%)]\tLoss: 0.021066\n",
            "Train Epoch: 24 [32640/35339 (92%)]\tLoss: 0.048691\n",
            "Train Epoch: 24 [33280/35339 (94%)]\tLoss: 0.000364\n",
            "Train Epoch: 24 [33920/35339 (96%)]\tLoss: 0.065102\n",
            "Train Epoch: 24 [34560/35339 (98%)]\tLoss: 0.001486\n",
            "Train Epoch: 24 [35200/35339 (99%)]\tLoss: 0.006258\n",
            "\n",
            "Validation set: Average loss: 0.0950, Accuracy: 3785/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_24.pth.\n",
            "Train Epoch: 25 [0/35339 (0%)]\tLoss: 0.011185\n",
            "Train Epoch: 25 [640/35339 (2%)]\tLoss: 0.004472\n",
            "Train Epoch: 25 [1280/35339 (4%)]\tLoss: 0.013517\n",
            "Train Epoch: 25 [1920/35339 (5%)]\tLoss: 0.000067\n",
            "Train Epoch: 25 [2560/35339 (7%)]\tLoss: 0.000514\n",
            "Train Epoch: 25 [3200/35339 (9%)]\tLoss: 0.016759\n",
            "Train Epoch: 25 [3840/35339 (11%)]\tLoss: 0.001218\n",
            "Train Epoch: 25 [4480/35339 (13%)]\tLoss: 0.000972\n",
            "Train Epoch: 25 [5120/35339 (14%)]\tLoss: 0.003054\n",
            "Train Epoch: 25 [5760/35339 (16%)]\tLoss: 0.002595\n",
            "Train Epoch: 25 [6400/35339 (18%)]\tLoss: 0.000173\n",
            "Train Epoch: 25 [7040/35339 (20%)]\tLoss: 0.001185\n",
            "Train Epoch: 25 [7680/35339 (22%)]\tLoss: 0.003656\n",
            "Train Epoch: 25 [8320/35339 (24%)]\tLoss: 0.004717\n",
            "Train Epoch: 25 [8960/35339 (25%)]\tLoss: 0.019415\n",
            "Train Epoch: 25 [9600/35339 (27%)]\tLoss: 0.003309\n",
            "Train Epoch: 25 [10240/35339 (29%)]\tLoss: 0.036166\n",
            "Train Epoch: 25 [10880/35339 (31%)]\tLoss: 0.001253\n",
            "Train Epoch: 25 [11520/35339 (33%)]\tLoss: 0.003451\n",
            "Train Epoch: 25 [12160/35339 (34%)]\tLoss: 0.009701\n",
            "Train Epoch: 25 [12800/35339 (36%)]\tLoss: 0.027154\n",
            "Train Epoch: 25 [13440/35339 (38%)]\tLoss: 0.001524\n",
            "Train Epoch: 25 [14080/35339 (40%)]\tLoss: 0.057294\n",
            "Train Epoch: 25 [14720/35339 (42%)]\tLoss: 0.053821\n",
            "Train Epoch: 25 [15360/35339 (43%)]\tLoss: 0.003867\n",
            "Train Epoch: 25 [16000/35339 (45%)]\tLoss: 0.070216\n",
            "Train Epoch: 25 [16640/35339 (47%)]\tLoss: 0.122396\n",
            "Train Epoch: 25 [17280/35339 (49%)]\tLoss: 0.046502\n",
            "Train Epoch: 25 [17920/35339 (51%)]\tLoss: 0.071877\n",
            "Train Epoch: 25 [18560/35339 (52%)]\tLoss: 0.005667\n",
            "Train Epoch: 25 [19200/35339 (54%)]\tLoss: 0.001082\n",
            "Train Epoch: 25 [19840/35339 (56%)]\tLoss: 0.134931\n",
            "Train Epoch: 25 [20480/35339 (58%)]\tLoss: 0.003890\n",
            "Train Epoch: 25 [21120/35339 (60%)]\tLoss: 0.022712\n",
            "Train Epoch: 25 [21760/35339 (61%)]\tLoss: 0.001291\n",
            "Train Epoch: 25 [22400/35339 (63%)]\tLoss: 0.028782\n",
            "Train Epoch: 25 [23040/35339 (65%)]\tLoss: 0.089241\n",
            "Train Epoch: 25 [23680/35339 (67%)]\tLoss: 0.001965\n",
            "Train Epoch: 25 [24320/35339 (69%)]\tLoss: 0.100392\n",
            "Train Epoch: 25 [24960/35339 (71%)]\tLoss: 0.037959\n",
            "Train Epoch: 25 [25600/35339 (72%)]\tLoss: 0.170001\n",
            "Train Epoch: 25 [26240/35339 (74%)]\tLoss: 0.002382\n",
            "Train Epoch: 25 [26880/35339 (76%)]\tLoss: 0.006543\n",
            "Train Epoch: 25 [27520/35339 (78%)]\tLoss: 0.006067\n",
            "Train Epoch: 25 [28160/35339 (80%)]\tLoss: 0.004360\n",
            "Train Epoch: 25 [28800/35339 (81%)]\tLoss: 0.009039\n",
            "Train Epoch: 25 [29440/35339 (83%)]\tLoss: 0.003668\n",
            "Train Epoch: 25 [30080/35339 (85%)]\tLoss: 0.000579\n",
            "Train Epoch: 25 [30720/35339 (87%)]\tLoss: 0.002634\n",
            "Train Epoch: 25 [31360/35339 (89%)]\tLoss: 0.022331\n",
            "Train Epoch: 25 [32000/35339 (90%)]\tLoss: 0.006466\n",
            "Train Epoch: 25 [32640/35339 (92%)]\tLoss: 0.002891\n",
            "Train Epoch: 25 [33280/35339 (94%)]\tLoss: 0.000691\n",
            "Train Epoch: 25 [33920/35339 (96%)]\tLoss: 0.058268\n",
            "Train Epoch: 25 [34560/35339 (98%)]\tLoss: 0.013153\n",
            "Train Epoch: 25 [35200/35339 (99%)]\tLoss: 0.010293\n",
            "\n",
            "Validation set: Average loss: 0.0983, Accuracy: 3774/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_25.pth.\n",
            "Train Epoch: 26 [0/35339 (0%)]\tLoss: 0.004618\n",
            "Train Epoch: 26 [640/35339 (2%)]\tLoss: 0.070988\n",
            "Train Epoch: 26 [1280/35339 (4%)]\tLoss: 0.088937\n",
            "Train Epoch: 26 [1920/35339 (5%)]\tLoss: 0.004167\n",
            "Train Epoch: 26 [2560/35339 (7%)]\tLoss: 0.004257\n",
            "Train Epoch: 26 [3200/35339 (9%)]\tLoss: 0.007206\n",
            "Train Epoch: 26 [3840/35339 (11%)]\tLoss: 0.002256\n",
            "Train Epoch: 26 [4480/35339 (13%)]\tLoss: 0.000053\n",
            "Train Epoch: 26 [5120/35339 (14%)]\tLoss: 0.009088\n",
            "Train Epoch: 26 [5760/35339 (16%)]\tLoss: 0.018956\n",
            "Train Epoch: 26 [6400/35339 (18%)]\tLoss: 0.004856\n",
            "Train Epoch: 26 [7040/35339 (20%)]\tLoss: 0.004136\n",
            "Train Epoch: 26 [7680/35339 (22%)]\tLoss: 0.002139\n",
            "Train Epoch: 26 [8320/35339 (24%)]\tLoss: 0.046328\n",
            "Train Epoch: 26 [8960/35339 (25%)]\tLoss: 0.006480\n",
            "Train Epoch: 26 [9600/35339 (27%)]\tLoss: 0.036545\n",
            "Train Epoch: 26 [10240/35339 (29%)]\tLoss: 0.000166\n",
            "Train Epoch: 26 [10880/35339 (31%)]\tLoss: 0.003107\n",
            "Train Epoch: 26 [11520/35339 (33%)]\tLoss: 0.004743\n",
            "Train Epoch: 26 [12160/35339 (34%)]\tLoss: 0.007525\n",
            "Train Epoch: 26 [12800/35339 (36%)]\tLoss: 0.008004\n",
            "Train Epoch: 26 [13440/35339 (38%)]\tLoss: 0.009367\n",
            "Train Epoch: 26 [14080/35339 (40%)]\tLoss: 0.054050\n",
            "Train Epoch: 26 [14720/35339 (42%)]\tLoss: 0.018942\n",
            "Train Epoch: 26 [15360/35339 (43%)]\tLoss: 0.014877\n",
            "Train Epoch: 26 [16000/35339 (45%)]\tLoss: 0.000519\n",
            "Train Epoch: 26 [16640/35339 (47%)]\tLoss: 0.001514\n",
            "Train Epoch: 26 [17280/35339 (49%)]\tLoss: 0.000331\n",
            "Train Epoch: 26 [17920/35339 (51%)]\tLoss: 0.007940\n",
            "Train Epoch: 26 [18560/35339 (52%)]\tLoss: 0.054771\n",
            "Train Epoch: 26 [19200/35339 (54%)]\tLoss: 0.077777\n",
            "Train Epoch: 26 [19840/35339 (56%)]\tLoss: 0.001556\n",
            "Train Epoch: 26 [20480/35339 (58%)]\tLoss: 0.000490\n",
            "Train Epoch: 26 [21120/35339 (60%)]\tLoss: 0.008610\n",
            "Train Epoch: 26 [21760/35339 (61%)]\tLoss: 0.000868\n",
            "Train Epoch: 26 [22400/35339 (63%)]\tLoss: 0.023597\n",
            "Train Epoch: 26 [23040/35339 (65%)]\tLoss: 0.040926\n",
            "Train Epoch: 26 [23680/35339 (67%)]\tLoss: 0.003660\n",
            "Train Epoch: 26 [24320/35339 (69%)]\tLoss: 0.000350\n",
            "Train Epoch: 26 [24960/35339 (71%)]\tLoss: 0.008062\n",
            "Train Epoch: 26 [25600/35339 (72%)]\tLoss: 0.002968\n",
            "Train Epoch: 26 [26240/35339 (74%)]\tLoss: 0.000444\n",
            "Train Epoch: 26 [26880/35339 (76%)]\tLoss: 0.004017\n",
            "Train Epoch: 26 [27520/35339 (78%)]\tLoss: 0.009699\n",
            "Train Epoch: 26 [28160/35339 (80%)]\tLoss: 0.011978\n",
            "Train Epoch: 26 [28800/35339 (81%)]\tLoss: 0.005374\n",
            "Train Epoch: 26 [29440/35339 (83%)]\tLoss: 0.003114\n",
            "Train Epoch: 26 [30080/35339 (85%)]\tLoss: 0.001119\n",
            "Train Epoch: 26 [30720/35339 (87%)]\tLoss: 0.000456\n",
            "Train Epoch: 26 [31360/35339 (89%)]\tLoss: 0.123616\n",
            "Train Epoch: 26 [32000/35339 (90%)]\tLoss: 0.055838\n",
            "Train Epoch: 26 [32640/35339 (92%)]\tLoss: 0.001773\n",
            "Train Epoch: 26 [33280/35339 (94%)]\tLoss: 0.001594\n",
            "Train Epoch: 26 [33920/35339 (96%)]\tLoss: 0.012345\n",
            "Train Epoch: 26 [34560/35339 (98%)]\tLoss: 0.008704\n",
            "Train Epoch: 26 [35200/35339 (99%)]\tLoss: 0.006178\n",
            "\n",
            "Validation set: Average loss: 0.0952, Accuracy: 3761/3870 (97%)\n",
            "\n",
            "\n",
            "Saved model to model_26.pth.\n",
            "Train Epoch: 27 [0/35339 (0%)]\tLoss: 0.005986\n",
            "Train Epoch: 27 [640/35339 (2%)]\tLoss: 0.000254\n",
            "Train Epoch: 27 [1280/35339 (4%)]\tLoss: 0.000951\n",
            "Train Epoch: 27 [1920/35339 (5%)]\tLoss: 0.018926\n",
            "Train Epoch: 27 [2560/35339 (7%)]\tLoss: 0.014039\n",
            "Train Epoch: 27 [3200/35339 (9%)]\tLoss: 0.016608\n",
            "Train Epoch: 27 [3840/35339 (11%)]\tLoss: 0.020466\n",
            "Train Epoch: 27 [4480/35339 (13%)]\tLoss: 0.017350\n",
            "Train Epoch: 27 [5120/35339 (14%)]\tLoss: 0.006675\n",
            "Train Epoch: 27 [5760/35339 (16%)]\tLoss: 0.007919\n",
            "Train Epoch: 27 [6400/35339 (18%)]\tLoss: 0.000274\n",
            "Train Epoch: 27 [7040/35339 (20%)]\tLoss: 0.005130\n",
            "Train Epoch: 27 [7680/35339 (22%)]\tLoss: 0.002845\n",
            "Train Epoch: 27 [8320/35339 (24%)]\tLoss: 0.015345\n",
            "Train Epoch: 27 [8960/35339 (25%)]\tLoss: 0.005030\n",
            "Train Epoch: 27 [9600/35339 (27%)]\tLoss: 0.090791\n",
            "Train Epoch: 27 [10240/35339 (29%)]\tLoss: 0.000423\n",
            "Train Epoch: 27 [10880/35339 (31%)]\tLoss: 0.000229\n",
            "Train Epoch: 27 [11520/35339 (33%)]\tLoss: 0.013428\n",
            "Train Epoch: 27 [12160/35339 (34%)]\tLoss: 0.069382\n",
            "Train Epoch: 27 [12800/35339 (36%)]\tLoss: 0.000062\n",
            "Train Epoch: 27 [13440/35339 (38%)]\tLoss: 0.009943\n",
            "Train Epoch: 27 [14080/35339 (40%)]\tLoss: 0.004091\n",
            "Train Epoch: 27 [14720/35339 (42%)]\tLoss: 0.073117\n",
            "Train Epoch: 27 [15360/35339 (43%)]\tLoss: 0.000982\n",
            "Train Epoch: 27 [16000/35339 (45%)]\tLoss: 0.000880\n",
            "Train Epoch: 27 [16640/35339 (47%)]\tLoss: 0.000187\n",
            "Train Epoch: 27 [17280/35339 (49%)]\tLoss: 0.004289\n",
            "Train Epoch: 27 [17920/35339 (51%)]\tLoss: 0.043207\n",
            "Train Epoch: 27 [18560/35339 (52%)]\tLoss: 0.012305\n",
            "Train Epoch: 27 [19200/35339 (54%)]\tLoss: 0.000523\n",
            "Train Epoch: 27 [19840/35339 (56%)]\tLoss: 0.096158\n",
            "Train Epoch: 27 [20480/35339 (58%)]\tLoss: 0.011271\n",
            "Train Epoch: 27 [21120/35339 (60%)]\tLoss: 0.003008\n",
            "Train Epoch: 27 [21760/35339 (61%)]\tLoss: 0.032479\n",
            "Train Epoch: 27 [22400/35339 (63%)]\tLoss: 0.001001\n",
            "Train Epoch: 27 [23040/35339 (65%)]\tLoss: 0.017743\n",
            "Train Epoch: 27 [23680/35339 (67%)]\tLoss: 0.007063\n",
            "Train Epoch: 27 [24320/35339 (69%)]\tLoss: 0.003316\n",
            "Train Epoch: 27 [24960/35339 (71%)]\tLoss: 0.001768\n",
            "Train Epoch: 27 [25600/35339 (72%)]\tLoss: 0.016245\n",
            "Train Epoch: 27 [26240/35339 (74%)]\tLoss: 0.042710\n",
            "Train Epoch: 27 [26880/35339 (76%)]\tLoss: 0.041383\n",
            "Train Epoch: 27 [27520/35339 (78%)]\tLoss: 0.000605\n",
            "Train Epoch: 27 [28160/35339 (80%)]\tLoss: 0.012016\n",
            "Train Epoch: 27 [28800/35339 (81%)]\tLoss: 0.000257\n",
            "Train Epoch: 27 [29440/35339 (83%)]\tLoss: 0.003241\n",
            "Train Epoch: 27 [30080/35339 (85%)]\tLoss: 0.002777\n",
            "Train Epoch: 27 [30720/35339 (87%)]\tLoss: 0.049554\n",
            "Train Epoch: 27 [31360/35339 (89%)]\tLoss: 0.104680\n",
            "Train Epoch: 27 [32000/35339 (90%)]\tLoss: 0.000142\n",
            "Train Epoch: 27 [32640/35339 (92%)]\tLoss: 0.010203\n",
            "Train Epoch: 27 [33280/35339 (94%)]\tLoss: 0.010726\n",
            "Train Epoch: 27 [33920/35339 (96%)]\tLoss: 0.149114\n",
            "Train Epoch: 27 [34560/35339 (98%)]\tLoss: 0.029637\n",
            "Train Epoch: 27 [35200/35339 (99%)]\tLoss: 0.007790\n",
            "\n",
            "Validation set: Average loss: 0.0972, Accuracy: 3785/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_27.pth.\n",
            "Train Epoch: 28 [0/35339 (0%)]\tLoss: 0.000127\n",
            "Train Epoch: 28 [640/35339 (2%)]\tLoss: 0.002212\n",
            "Train Epoch: 28 [1280/35339 (4%)]\tLoss: 0.008698\n",
            "Train Epoch: 28 [1920/35339 (5%)]\tLoss: 0.002922\n",
            "Train Epoch: 28 [2560/35339 (7%)]\tLoss: 0.001410\n",
            "Train Epoch: 28 [3200/35339 (9%)]\tLoss: 0.019649\n",
            "Train Epoch: 28 [3840/35339 (11%)]\tLoss: 0.003208\n",
            "Train Epoch: 28 [4480/35339 (13%)]\tLoss: 0.000157\n",
            "Train Epoch: 28 [5120/35339 (14%)]\tLoss: 0.017299\n",
            "Train Epoch: 28 [5760/35339 (16%)]\tLoss: 0.020572\n",
            "Train Epoch: 28 [6400/35339 (18%)]\tLoss: 0.000037\n",
            "Train Epoch: 28 [7040/35339 (20%)]\tLoss: 0.016159\n",
            "Train Epoch: 28 [7680/35339 (22%)]\tLoss: 0.006736\n",
            "Train Epoch: 28 [8320/35339 (24%)]\tLoss: 0.010071\n",
            "Train Epoch: 28 [8960/35339 (25%)]\tLoss: 0.037841\n",
            "Train Epoch: 28 [9600/35339 (27%)]\tLoss: 0.086898\n",
            "Train Epoch: 28 [10240/35339 (29%)]\tLoss: 0.016909\n",
            "Train Epoch: 28 [10880/35339 (31%)]\tLoss: 0.004719\n",
            "Train Epoch: 28 [11520/35339 (33%)]\tLoss: 0.011331\n",
            "Train Epoch: 28 [12160/35339 (34%)]\tLoss: 0.112972\n",
            "Train Epoch: 28 [12800/35339 (36%)]\tLoss: 0.001581\n",
            "Train Epoch: 28 [13440/35339 (38%)]\tLoss: 0.077925\n",
            "Train Epoch: 28 [14080/35339 (40%)]\tLoss: 0.005042\n",
            "Train Epoch: 28 [14720/35339 (42%)]\tLoss: 0.005110\n",
            "Train Epoch: 28 [15360/35339 (43%)]\tLoss: 0.001655\n",
            "Train Epoch: 28 [16000/35339 (45%)]\tLoss: 0.002820\n",
            "Train Epoch: 28 [16640/35339 (47%)]\tLoss: 0.027873\n",
            "Train Epoch: 28 [17280/35339 (49%)]\tLoss: 0.000845\n",
            "Train Epoch: 28 [17920/35339 (51%)]\tLoss: 0.018652\n",
            "Train Epoch: 28 [18560/35339 (52%)]\tLoss: 0.005057\n",
            "Train Epoch: 28 [19200/35339 (54%)]\tLoss: 0.000299\n",
            "Train Epoch: 28 [19840/35339 (56%)]\tLoss: 0.000762\n",
            "Train Epoch: 28 [20480/35339 (58%)]\tLoss: 0.009426\n",
            "Train Epoch: 28 [21120/35339 (60%)]\tLoss: 0.000542\n",
            "Train Epoch: 28 [21760/35339 (61%)]\tLoss: 0.008729\n",
            "Train Epoch: 28 [22400/35339 (63%)]\tLoss: 0.002496\n",
            "Train Epoch: 28 [23040/35339 (65%)]\tLoss: 0.002032\n",
            "Train Epoch: 28 [23680/35339 (67%)]\tLoss: 0.000192\n",
            "Train Epoch: 28 [24320/35339 (69%)]\tLoss: 0.023017\n",
            "Train Epoch: 28 [24960/35339 (71%)]\tLoss: 0.019973\n",
            "Train Epoch: 28 [25600/35339 (72%)]\tLoss: 0.129589\n",
            "Train Epoch: 28 [26240/35339 (74%)]\tLoss: 0.004503\n",
            "Train Epoch: 28 [26880/35339 (76%)]\tLoss: 0.047964\n",
            "Train Epoch: 28 [27520/35339 (78%)]\tLoss: 0.018523\n",
            "Train Epoch: 28 [28160/35339 (80%)]\tLoss: 0.012432\n",
            "Train Epoch: 28 [28800/35339 (81%)]\tLoss: 0.002275\n",
            "Train Epoch: 28 [29440/35339 (83%)]\tLoss: 0.017483\n",
            "Train Epoch: 28 [30080/35339 (85%)]\tLoss: 0.000194\n",
            "Train Epoch: 28 [30720/35339 (87%)]\tLoss: 0.000340\n",
            "Train Epoch: 28 [31360/35339 (89%)]\tLoss: 0.013732\n",
            "Train Epoch: 28 [32000/35339 (90%)]\tLoss: 0.005228\n",
            "Train Epoch: 28 [32640/35339 (92%)]\tLoss: 0.020034\n",
            "Train Epoch: 28 [33280/35339 (94%)]\tLoss: 0.003500\n",
            "Train Epoch: 28 [33920/35339 (96%)]\tLoss: 0.015488\n",
            "Train Epoch: 28 [34560/35339 (98%)]\tLoss: 0.000024\n",
            "Train Epoch: 28 [35200/35339 (99%)]\tLoss: 0.146525\n",
            "\n",
            "Validation set: Average loss: 0.0886, Accuracy: 3790/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_28.pth.\n",
            "\n",
            "Most accurate epoch so far: 28\n",
            "Train Epoch: 29 [0/35339 (0%)]\tLoss: 0.079854\n",
            "Train Epoch: 29 [640/35339 (2%)]\tLoss: 0.005813\n",
            "Train Epoch: 29 [1280/35339 (4%)]\tLoss: 0.014587\n",
            "Train Epoch: 29 [1920/35339 (5%)]\tLoss: 0.057638\n",
            "Train Epoch: 29 [2560/35339 (7%)]\tLoss: 0.014642\n",
            "Train Epoch: 29 [3200/35339 (9%)]\tLoss: 0.070222\n",
            "Train Epoch: 29 [3840/35339 (11%)]\tLoss: 0.006302\n",
            "Train Epoch: 29 [4480/35339 (13%)]\tLoss: 0.002455\n",
            "Train Epoch: 29 [5120/35339 (14%)]\tLoss: 0.002018\n",
            "Train Epoch: 29 [5760/35339 (16%)]\tLoss: 0.051575\n",
            "Train Epoch: 29 [6400/35339 (18%)]\tLoss: 0.000207\n",
            "Train Epoch: 29 [7040/35339 (20%)]\tLoss: 0.016715\n",
            "Train Epoch: 29 [7680/35339 (22%)]\tLoss: 0.004392\n",
            "Train Epoch: 29 [8320/35339 (24%)]\tLoss: 0.019987\n",
            "Train Epoch: 29 [8960/35339 (25%)]\tLoss: 0.001320\n",
            "Train Epoch: 29 [9600/35339 (27%)]\tLoss: 0.056625\n",
            "Train Epoch: 29 [10240/35339 (29%)]\tLoss: 0.001272\n",
            "Train Epoch: 29 [10880/35339 (31%)]\tLoss: 0.059677\n",
            "Train Epoch: 29 [11520/35339 (33%)]\tLoss: 0.004750\n",
            "Train Epoch: 29 [12160/35339 (34%)]\tLoss: 0.018034\n",
            "Train Epoch: 29 [12800/35339 (36%)]\tLoss: 0.003684\n",
            "Train Epoch: 29 [13440/35339 (38%)]\tLoss: 0.109474\n",
            "Train Epoch: 29 [14080/35339 (40%)]\tLoss: 0.013734\n",
            "Train Epoch: 29 [14720/35339 (42%)]\tLoss: 0.001349\n",
            "Train Epoch: 29 [15360/35339 (43%)]\tLoss: 0.001741\n",
            "Train Epoch: 29 [16000/35339 (45%)]\tLoss: 0.028839\n",
            "Train Epoch: 29 [16640/35339 (47%)]\tLoss: 0.003037\n",
            "Train Epoch: 29 [17280/35339 (49%)]\tLoss: 0.004014\n",
            "Train Epoch: 29 [17920/35339 (51%)]\tLoss: 0.002225\n",
            "Train Epoch: 29 [18560/35339 (52%)]\tLoss: 0.021212\n",
            "Train Epoch: 29 [19200/35339 (54%)]\tLoss: 0.000626\n",
            "Train Epoch: 29 [19840/35339 (56%)]\tLoss: 0.002884\n",
            "Train Epoch: 29 [20480/35339 (58%)]\tLoss: 0.001250\n",
            "Train Epoch: 29 [21120/35339 (60%)]\tLoss: 0.000767\n",
            "Train Epoch: 29 [21760/35339 (61%)]\tLoss: 0.004608\n",
            "Train Epoch: 29 [22400/35339 (63%)]\tLoss: 0.000080\n",
            "Train Epoch: 29 [23040/35339 (65%)]\tLoss: 0.000090\n",
            "Train Epoch: 29 [23680/35339 (67%)]\tLoss: 0.166305\n",
            "Train Epoch: 29 [24320/35339 (69%)]\tLoss: 0.000270\n",
            "Train Epoch: 29 [24960/35339 (71%)]\tLoss: 0.001089\n",
            "Train Epoch: 29 [25600/35339 (72%)]\tLoss: 0.007384\n",
            "Train Epoch: 29 [26240/35339 (74%)]\tLoss: 0.000689\n",
            "Train Epoch: 29 [26880/35339 (76%)]\tLoss: 0.059366\n",
            "Train Epoch: 29 [27520/35339 (78%)]\tLoss: 0.006383\n",
            "Train Epoch: 29 [28160/35339 (80%)]\tLoss: 0.061556\n",
            "Train Epoch: 29 [28800/35339 (81%)]\tLoss: 0.000328\n",
            "Train Epoch: 29 [29440/35339 (83%)]\tLoss: 0.002844\n",
            "Train Epoch: 29 [30080/35339 (85%)]\tLoss: 0.018383\n",
            "Train Epoch: 29 [30720/35339 (87%)]\tLoss: 0.004949\n",
            "Train Epoch: 29 [31360/35339 (89%)]\tLoss: 0.029325\n",
            "Train Epoch: 29 [32000/35339 (90%)]\tLoss: 0.002124\n",
            "Train Epoch: 29 [32640/35339 (92%)]\tLoss: 0.000447\n",
            "Train Epoch: 29 [33280/35339 (94%)]\tLoss: 0.032939\n",
            "Train Epoch: 29 [33920/35339 (96%)]\tLoss: 0.025779\n",
            "Train Epoch: 29 [34560/35339 (98%)]\tLoss: 0.000147\n",
            "Train Epoch: 29 [35200/35339 (99%)]\tLoss: 0.009382\n",
            "\n",
            "Validation set: Average loss: 0.0919, Accuracy: 3778/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_29.pth.\n",
            "Train Epoch: 30 [0/35339 (0%)]\tLoss: 0.013022\n",
            "Train Epoch: 30 [640/35339 (2%)]\tLoss: 0.000568\n",
            "Train Epoch: 30 [1280/35339 (4%)]\tLoss: 0.058234\n",
            "Train Epoch: 30 [1920/35339 (5%)]\tLoss: 0.000155\n",
            "Train Epoch: 30 [2560/35339 (7%)]\tLoss: 0.006670\n",
            "Train Epoch: 30 [3200/35339 (9%)]\tLoss: 0.245392\n",
            "Train Epoch: 30 [3840/35339 (11%)]\tLoss: 0.009594\n",
            "Train Epoch: 30 [4480/35339 (13%)]\tLoss: 0.000067\n",
            "Train Epoch: 30 [5120/35339 (14%)]\tLoss: 0.009527\n",
            "Train Epoch: 30 [5760/35339 (16%)]\tLoss: 0.003236\n",
            "Train Epoch: 30 [6400/35339 (18%)]\tLoss: 0.015634\n",
            "Train Epoch: 30 [7040/35339 (20%)]\tLoss: 0.003020\n",
            "Train Epoch: 30 [7680/35339 (22%)]\tLoss: 0.038589\n",
            "Train Epoch: 30 [8320/35339 (24%)]\tLoss: 0.004157\n",
            "Train Epoch: 30 [8960/35339 (25%)]\tLoss: 0.004630\n",
            "Train Epoch: 30 [9600/35339 (27%)]\tLoss: 0.002710\n",
            "Train Epoch: 30 [10240/35339 (29%)]\tLoss: 0.000505\n",
            "Train Epoch: 30 [10880/35339 (31%)]\tLoss: 0.048043\n",
            "Train Epoch: 30 [11520/35339 (33%)]\tLoss: 0.000278\n",
            "Train Epoch: 30 [12160/35339 (34%)]\tLoss: 0.017582\n",
            "Train Epoch: 30 [12800/35339 (36%)]\tLoss: 0.000749\n",
            "Train Epoch: 30 [13440/35339 (38%)]\tLoss: 0.024643\n",
            "Train Epoch: 30 [14080/35339 (40%)]\tLoss: 0.009483\n",
            "Train Epoch: 30 [14720/35339 (42%)]\tLoss: 0.000405\n",
            "Train Epoch: 30 [15360/35339 (43%)]\tLoss: 0.253628\n",
            "Train Epoch: 30 [16000/35339 (45%)]\tLoss: 0.005253\n",
            "Train Epoch: 30 [16640/35339 (47%)]\tLoss: 0.045550\n",
            "Train Epoch: 30 [17280/35339 (49%)]\tLoss: 0.008162\n",
            "Train Epoch: 30 [17920/35339 (51%)]\tLoss: 0.006958\n",
            "Train Epoch: 30 [18560/35339 (52%)]\tLoss: 0.001014\n",
            "Train Epoch: 30 [19200/35339 (54%)]\tLoss: 0.079405\n",
            "Train Epoch: 30 [19840/35339 (56%)]\tLoss: 0.026528\n",
            "Train Epoch: 30 [20480/35339 (58%)]\tLoss: 0.001810\n",
            "Train Epoch: 30 [21120/35339 (60%)]\tLoss: 0.001026\n",
            "Train Epoch: 30 [21760/35339 (61%)]\tLoss: 0.034665\n",
            "Train Epoch: 30 [22400/35339 (63%)]\tLoss: 0.008318\n",
            "Train Epoch: 30 [23040/35339 (65%)]\tLoss: 0.002722\n",
            "Train Epoch: 30 [23680/35339 (67%)]\tLoss: 0.057432\n",
            "Train Epoch: 30 [24320/35339 (69%)]\tLoss: 0.030082\n",
            "Train Epoch: 30 [24960/35339 (71%)]\tLoss: 0.011304\n",
            "Train Epoch: 30 [25600/35339 (72%)]\tLoss: 0.052491\n",
            "Train Epoch: 30 [26240/35339 (74%)]\tLoss: 0.022596\n",
            "Train Epoch: 30 [26880/35339 (76%)]\tLoss: 0.000399\n",
            "Train Epoch: 30 [27520/35339 (78%)]\tLoss: 0.038633\n",
            "Train Epoch: 30 [28160/35339 (80%)]\tLoss: 0.001121\n",
            "Train Epoch: 30 [28800/35339 (81%)]\tLoss: 0.000096\n",
            "Train Epoch: 30 [29440/35339 (83%)]\tLoss: 0.002558\n",
            "Train Epoch: 30 [30080/35339 (85%)]\tLoss: 0.040509\n",
            "Train Epoch: 30 [30720/35339 (87%)]\tLoss: 0.010034\n",
            "Train Epoch: 30 [31360/35339 (89%)]\tLoss: 0.039407\n",
            "Train Epoch: 30 [32000/35339 (90%)]\tLoss: 0.042180\n",
            "Train Epoch: 30 [32640/35339 (92%)]\tLoss: 0.000030\n",
            "Train Epoch: 30 [33280/35339 (94%)]\tLoss: 0.017585\n",
            "Train Epoch: 30 [33920/35339 (96%)]\tLoss: 0.014365\n",
            "Train Epoch: 30 [34560/35339 (98%)]\tLoss: 0.009606\n",
            "Train Epoch: 30 [35200/35339 (99%)]\tLoss: 0.069267\n",
            "\n",
            "Validation set: Average loss: 0.0683, Accuracy: 3811/3870 (98%)\n",
            "\n",
            "\n",
            "Saved model to model_30.pth.\n",
            "\n",
            "Most accurate epoch so far: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5D1KdCO6Gqo"
      },
      "source": [
        "#Plot training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y64tOSEF6RJ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b427a979-d512-4710-8170-2f30cd82b533"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_range = list(range(epochs))\n",
        "\n",
        "plt.plot(epoch_range,training_accuracy)\n",
        "plt.plot(epoch_range,validation_accuracy)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
        "plt.ylabel(u'Accuracy')\n",
        "plt.xlabel(u'Epochs')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVN1f1p7w59X"
      },
      "source": [
        "# Evaluate and Submit to Kaggle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BM5qP64w5zB",
        "outputId": "0139d953-44b6-41d2-cee7-7ed041446b8d"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "outfile = 'gtsrb_kaggle.csv'\n",
        "\n",
        "output_file = open(outfile, \"w\")\n",
        "dataframe_dict = {\"Filename\" : [], \"ClassId\": []}\n",
        "\n",
        "test_data = torch.load('testing/test.pt')\n",
        "file_ids = pickle.load(open('testing/file_ids.pkl', 'rb'))\n",
        "\n",
        "model_file = 'model_' + str(best_epoch) + '.pth'\n",
        "model = Net() # TODO: load your model here, don't forget to put it on Eval mode !\n",
        "model.load_state_dict(torch.load(model_file))\n",
        "model.eval()\n",
        "\n",
        "for i, data in enumerate(test_data):\n",
        "    data = data.unsqueeze(0)\n",
        "\n",
        "    output = model(data)\n",
        "    pred = output.data.max(1, keepdim=True)[1].item()\n",
        "    file_id = file_ids[i][0:5]\n",
        "    dataframe_dict['Filename'].append(file_id)\n",
        "    dataframe_dict['ClassId'].append(pred)\n",
        "\n",
        "df = pd.DataFrame(data=dataframe_dict)\n",
        "df.to_csv(outfile, index=False)\n",
        "print(\"Written to csv file {}\".format(outfile))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Written to csv file gtsrb_kaggle.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhSl_4kn6sox"
      },
      "source": [
        "# Submitting to Kaggle\n",
        "\n",
        "Now take this csv file, download it from your Google drive and then submit it to Kaggle to check performance of your model."
      ]
    }
  ]
}